{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nedOeJNPHiir",
        "outputId": "02131b08-ff5b-4f1b-87d4-5a256610448d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Robustness-of-Bayesian-Neural-Networks-against-White-Box-Attacks'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 102 (delta 26), reused 69 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 924.32 KiB | 7.90 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Soumik-Roy/Robustness-of-Bayesian-Neural-Networks-against-White-Box-Attacks.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OkUg1GQRnIx"
      },
      "outputs": [],
      "source": [
        "!cp -a Robustness-of-Bayesian-Neural-Networks-against-White-Box-Attacks/. ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhYL5Q1NSA6K"
      },
      "outputs": [],
      "source": [
        "!rm -r ./Robustness-of-Bayesian-Neural-Networks-against-White-Box-Attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlO1LgW1GpKr"
      },
      "source": [
        "# Bayesian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HdAhp-mwy3b"
      },
      "source": [
        "### Lenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXZffVijGyjD",
        "outputId": "de868428-70fe-4f07-c273-eb145cb4ed82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-02 03:09:31.426494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-02 03:09:32.425305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parameters initialized\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 77017159.75it/s]\n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 86525495.59it/s]\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 27042243.01it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 26132412.58it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch: 0 \tTraining Loss: 68325.9913 \tTraining Accuracy: 10.2934 \tValidation Loss: 297446.7963 \tValidation Accuracy: 10.4068 \ttrain_kl_div: 7203156.9761\n",
            "Validation loss decreased (inf --> 297446.796278).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 35977.0538 \tTraining Accuracy: 10.8419 \tValidation Loss: 264340.9375 \tValidation Accuracy: 11.4955 \ttrain_kl_div: 6131598.3936\n",
            "Validation loss decreased (297446.796278 --> 264340.937538).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 30759.7078 \tTraining Accuracy: 14.8063 \tValidation Loss: 230062.3053 \tValidation Accuracy: 53.7365 \ttrain_kl_div: 5238211.9761\n",
            "Validation loss decreased (264340.937538 --> 230062.305287).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 26778.6398 \tTraining Accuracy: 11.0144 \tValidation Loss: 146934.7022 \tValidation Accuracy: 10.2726 \ttrain_kl_div: 3410240.8896\n",
            "Validation loss decreased (230062.305287 --> 146934.702152).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 17827.9156 \tTraining Accuracy: 10.2539 \tValidation Loss: 102056.1549 \tValidation Accuracy: 10.8900 \ttrain_kl_div: 2389166.9508\n",
            "Validation loss decreased (146934.702152 --> 102056.154924).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 12826.0573 \tTraining Accuracy: 10.2913 \tValidation Loss: 79817.1689 \tValidation Accuracy: 10.2227 \ttrain_kl_div: 1869967.3298\n",
            "Validation loss decreased (102056.154924 --> 79817.168862).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 10263.3465 \tTraining Accuracy: 10.2872 \tValidation Loss: 65636.4421 \tValidation Accuracy: 10.7713 \ttrain_kl_div: 1538114.5259\n",
            "Validation loss decreased (79817.168862 --> 65636.442133).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 8585.9792 \tTraining Accuracy: 10.6674 \tValidation Loss: 55506.0983 \tValidation Accuracy: 10.6620 \ttrain_kl_div: 1299652.0918\n",
            "Validation loss decreased (65636.442133 --> 55506.098302).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 7364.3280 \tTraining Accuracy: 10.4970 \tValidation Loss: 47602.0127 \tValidation Accuracy: 10.3628 \ttrain_kl_div: 1113032.1742\n",
            "Validation loss decreased (55506.098302 --> 47602.012707).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 6401.0540 \tTraining Accuracy: 10.4118 \tValidation Loss: 41151.8370 \tValidation Accuracy: 10.6751 \ttrain_kl_div: 960570.5186\n",
            "Validation loss decreased (47602.012707 --> 41151.837019).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 5610.9330 \tTraining Accuracy: 10.4243 \tValidation Loss: 35754.5073 \tValidation Accuracy: 10.4697 \ttrain_kl_div: 832885.6646\n",
            "Validation loss decreased (41151.837019 --> 35754.507255).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 4947.6976 \tTraining Accuracy: 10.3703 \tValidation Loss: 31217.7934 \tValidation Accuracy: 10.5730 \ttrain_kl_div: 725427.5682\n",
            "Validation loss decreased (35754.507255 --> 31217.793399).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 4388.0471 \tTraining Accuracy: 10.5053 \tValidation Loss: 27355.2261 \tValidation Accuracy: 10.5932 \ttrain_kl_div: 633857.3215\n",
            "Validation loss decreased (31217.793399 --> 27355.226129).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 3910.7330 \tTraining Accuracy: 10.3994 \tValidation Loss: 24042.5424 \tValidation Accuracy: 10.3605 \ttrain_kl_div: 555339.4182\n",
            "Validation loss decreased (27355.226129 --> 24042.542379).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 3500.7969 \tTraining Accuracy: 10.2851 \tValidation Loss: 21174.2401 \tValidation Accuracy: 10.6620 \ttrain_kl_div: 487355.2362\n",
            "Validation loss decreased (24042.542379 --> 21174.240086).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 3145.4462 \tTraining Accuracy: 10.2913 \tValidation Loss: 18680.8876 \tValidation Accuracy: 10.4531 \ttrain_kl_div: 428246.6690\n",
            "Validation loss decreased (21174.240086 --> 18680.887619).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 2836.4084 \tTraining Accuracy: 10.5552 \tValidation Loss: 16506.8184 \tValidation Accuracy: 9.8155 \ttrain_kl_div: 376688.1832\n",
            "Validation loss decreased (18680.887619 --> 16506.818415).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 2567.2580 \tTraining Accuracy: 10.3765 \tValidation Loss: 14605.1866 \tValidation Accuracy: 10.0363 \ttrain_kl_div: 331585.3258\n",
            "Validation loss decreased (16506.818415 --> 14605.186604).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 2331.2588 \tTraining Accuracy: 10.3682 \tValidation Loss: 12933.4342 \tValidation Accuracy: 10.7226 \ttrain_kl_div: 291951.9171\n",
            "Validation loss decreased (14605.186604 --> 12933.434165).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 2124.1174 \tTraining Accuracy: 10.1105 \tValidation Loss: 11465.4226 \tValidation Accuracy: 10.9339 \ttrain_kl_div: 257101.0497\n",
            "Validation loss decreased (12933.434165 --> 11465.422555).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 1941.6796 \tTraining Accuracy: 10.3682 \tValidation Loss: 10164.2043 \tValidation Accuracy: 10.4733 \ttrain_kl_div: 226327.1725\n",
            "Validation loss decreased (11465.422555 --> 10164.204347).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 1780.2707 \tTraining Accuracy: 10.3495 \tValidation Loss: 9021.6635 \tValidation Accuracy: 10.6169 \ttrain_kl_div: 199202.1513\n",
            "Validation loss decreased (10164.204347 --> 9021.663507).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 1638.4456 \tTraining Accuracy: 10.4492 \tValidation Loss: 8008.9961 \tValidation Accuracy: 11.0242 \ttrain_kl_div: 175204.0578\n",
            "Validation loss decreased (9021.663507 --> 8008.996076).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 1512.6729 \tTraining Accuracy: 10.3308 \tValidation Loss: 7112.7598 \tValidation Accuracy: 10.5991 \ttrain_kl_div: 153982.5499\n",
            "Validation loss decreased (8008.996076 --> 7112.759754).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 1401.3826 \tTraining Accuracy: 10.3661 \tValidation Loss: 6318.3043 \tValidation Accuracy: 11.2889 \ttrain_kl_div: 135224.3656\n",
            "Validation loss decreased (7112.759754 --> 6318.304329).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 1302.7463 \tTraining Accuracy: 10.6404 \tValidation Loss: 5614.7078 \tValidation Accuracy: 11.1631 \ttrain_kl_div: 118554.2279\n",
            "Validation loss decreased (6318.304329 --> 5614.707838).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 1215.1803 \tTraining Accuracy: 10.2643 \tValidation Loss: 4990.3628 \tValidation Accuracy: 10.6098 \ttrain_kl_div: 103809.3876\n",
            "Validation loss decreased (5614.707838 --> 4990.362758).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 1137.4908 \tTraining Accuracy: 10.6238 \tValidation Loss: 4435.9555 \tValidation Accuracy: 11.3744 \ttrain_kl_div: 90727.6509\n",
            "Validation loss decreased (4990.362758 --> 4435.955544).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 1068.6660 \tTraining Accuracy: 10.4077 \tValidation Loss: 3946.5433 \tValidation Accuracy: 11.2367 \ttrain_kl_div: 79167.8033\n",
            "Validation loss decreased (4435.955544 --> 3946.543271).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 1007.5511 \tTraining Accuracy: 10.7609 \tValidation Loss: 3513.0407 \tValidation Accuracy: 10.6787 \ttrain_kl_div: 68912.5927\n",
            "Validation loss decreased (3946.543271 --> 3513.040682).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 953.7845 \tTraining Accuracy: 10.7443 \tValidation Loss: 3130.0541 \tValidation Accuracy: 11.4362 \ttrain_kl_div: 59915.7114\n",
            "Validation loss decreased (3513.040682 --> 3130.054076).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 906.3210 \tTraining Accuracy: 10.2913 \tValidation Loss: 2792.1225 \tValidation Accuracy: 10.4994 \ttrain_kl_div: 51898.2125\n",
            "Validation loss decreased (3130.054076 --> 2792.122488).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 864.0809 \tTraining Accuracy: 10.7131 \tValidation Loss: 2495.4136 \tValidation Accuracy: 10.9981 \ttrain_kl_div: 44876.4036\n",
            "Validation loss decreased (2792.122488 --> 2495.413629).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 827.2101 \tTraining Accuracy: 10.4534 \tValidation Loss: 2231.4238 \tValidation Accuracy: 11.2343 \ttrain_kl_div: 38675.8844\n",
            "Validation loss decreased (2495.413629 --> 2231.423784).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 794.4078 \tTraining Accuracy: 10.7484 \tValidation Loss: 2009.8132 \tValidation Accuracy: 10.5944 \ttrain_kl_div: 33398.7080\n",
            "Validation loss decreased (2231.423784 --> 2009.813216).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 766.6784 \tTraining Accuracy: 10.5593 \tValidation Loss: 1803.5946 \tValidation Accuracy: 10.8473 \ttrain_kl_div: 28538.2114\n",
            "Validation loss decreased (2009.813216 --> 1803.594634).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 740.9909 \tTraining Accuracy: 10.7962 \tValidation Loss: 1629.4142 \tValidation Accuracy: 10.8959 \ttrain_kl_div: 24426.3017\n",
            "Validation loss decreased (1803.594634 --> 1629.414165).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 719.3197 \tTraining Accuracy: 10.7941 \tValidation Loss: 1476.3766 \tValidation Accuracy: 11.3139 \ttrain_kl_div: 20765.5887\n",
            "Validation loss decreased (1629.414165 --> 1476.376574).  Saving model ...\n",
            "Epoch: 38 \tTraining Loss: 700.3728 \tTraining Accuracy: 10.6799 \tValidation Loss: 1347.5804 \tValidation Accuracy: 11.0515 \ttrain_kl_div: 17702.4076\n",
            "Validation loss decreased (1476.376574 --> 1347.580379).  Saving model ...\n",
            "Epoch: 39 \tTraining Loss: 684.6732 \tTraining Accuracy: 10.6051 \tValidation Loss: 1241.3613 \tValidation Accuracy: 10.8639 \ttrain_kl_div: 15150.9275\n",
            "Validation loss decreased (1347.580379 --> 1241.361342).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 670.9096 \tTraining Accuracy: 10.6986 \tValidation Loss: 1145.9325 \tValidation Accuracy: 11.1512 \ttrain_kl_div: 12910.2089\n",
            "Validation loss decreased (1241.361342 --> 1145.932511).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 658.9986 \tTraining Accuracy: 10.6819 \tValidation Loss: 1066.8170 \tValidation Accuracy: 11.2308 \ttrain_kl_div: 11001.9643\n",
            "Validation loss decreased (1145.932511 --> 1066.817011).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 649.1162 \tTraining Accuracy: 10.7941 \tValidation Loss: 1014.5695 \tValidation Accuracy: 11.4718 \ttrain_kl_div: 9636.2314\n",
            "Validation loss decreased (1066.817011 --> 1014.569526).  Saving model ...\n",
            "Epoch: 43 \tTraining Loss: 642.1451 \tTraining Accuracy: 10.6799 \tValidation Loss: 963.7878 \tValidation Accuracy: 11.3400 \ttrain_kl_div: 8387.9774\n",
            "Validation loss decreased (1014.569526 --> 963.787835).  Saving model ...\n",
            "Epoch: 44 \tTraining Loss: 635.4521 \tTraining Accuracy: 10.7297 \tValidation Loss: 924.2498 \tValidation Accuracy: 11.1346 \ttrain_kl_div: 7455.5081\n",
            "Validation loss decreased (963.787835 --> 924.249800).  Saving model ...\n",
            "Epoch: 45 \tTraining Loss: 630.2618 \tTraining Accuracy: 10.4181 \tValidation Loss: 889.3469 \tValidation Accuracy: 11.1287 \ttrain_kl_div: 6614.8991\n",
            "Validation loss decreased (924.249800 --> 889.346912).  Saving model ...\n",
            "Epoch: 46 \tTraining Loss: 625.6104 \tTraining Accuracy: 10.5344 \tValidation Loss: 871.4727 \tValidation Accuracy: 11.0788 \ttrain_kl_div: 6096.4990\n",
            "Validation loss decreased (889.346912 --> 871.472712).  Saving model ...\n",
            "Epoch: 47 \tTraining Loss: 622.9096 \tTraining Accuracy: 10.6986 \tValidation Loss: 862.0761 \tValidation Accuracy: 10.8829 \ttrain_kl_div: 5878.0173\n",
            "Validation loss decreased (871.472712 --> 862.076076).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 621.2275 \tTraining Accuracy: 10.7796 \tValidation Loss: 860.7058 \tValidation Accuracy: 10.8461 \ttrain_kl_div: 5837.5689\n",
            "Validation loss decreased (862.076076 --> 860.705807).  Saving model ...\n",
            "Epoch: 49 \tTraining Loss: 620.6397 \tTraining Accuracy: 10.5926 \tValidation Loss: 881.0998 \tValidation Accuracy: 10.3260 \ttrain_kl_div: 6219.8154\n",
            "Epoch: 50 \tTraining Loss: 621.9239 \tTraining Accuracy: 10.7048 \tValidation Loss: 900.0282 \tValidation Accuracy: 10.9909 \ttrain_kl_div: 6597.4106\n",
            "Epoch: 51 \tTraining Loss: 623.3658 \tTraining Accuracy: 10.8523 \tValidation Loss: 944.5503 \tValidation Accuracy: 10.8271 \ttrain_kl_div: 7505.2062\n",
            "Epoch: 52 \tTraining Loss: 627.3566 \tTraining Accuracy: 10.7380 \tValidation Loss: 1030.8867 \tValidation Accuracy: 11.2521 \ttrain_kl_div: 9326.7665\n",
            "Epoch: 53 \tTraining Loss: 635.4998 \tTraining Accuracy: 10.6612 \tValidation Loss: 1140.3350 \tValidation Accuracy: 10.1895 \ttrain_kl_div: 11656.0304\n",
            "Epoch: 54 \tTraining Loss: 645.5324 \tTraining Accuracy: 10.8087 \tValidation Loss: 1299.2316 \tValidation Accuracy: 10.8722 \ttrain_kl_div: 15085.3691\n",
            "Epoch 00056: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch: 55 \tTraining Loss: 661.1027 \tTraining Accuracy: 10.8066 \tValidation Loss: 1448.2055 \tValidation Accuracy: 10.8342 \ttrain_kl_div: 18314.9526\n",
            "Epoch: 56 \tTraining Loss: 693.8114 \tTraining Accuracy: 10.9396 \tValidation Loss: 1123.2425 \tValidation Accuracy: 11.0729 \ttrain_kl_div: 12956.9942\n",
            "Epoch: 57 \tTraining Loss: 654.5206 \tTraining Accuracy: 11.0372 \tValidation Loss: 942.3194 \tValidation Accuracy: 11.4492 \ttrain_kl_div: 8512.5859\n",
            "Epoch: 58 \tTraining Loss: 632.6581 \tTraining Accuracy: 10.8710 \tValidation Loss: 835.7841 \tValidation Accuracy: 10.8520 \ttrain_kl_div: 5877.2800\n",
            "Validation loss decreased (860.705807 --> 835.784054).  Saving model ...\n",
            "Epoch: 59 \tTraining Loss: 619.8701 \tTraining Accuracy: 10.7713 \tValidation Loss: 772.5765 \tValidation Accuracy: 11.0503 \ttrain_kl_div: 4305.4003\n",
            "Validation loss decreased (835.784054 --> 772.576521).  Saving model ...\n",
            "Epoch: 60 \tTraining Loss: 612.4478 \tTraining Accuracy: 10.4617 \tValidation Loss: 733.4304 \tValidation Accuracy: 11.2391 \ttrain_kl_div: 3332.8418\n",
            "Validation loss decreased (772.576521 --> 733.430415).  Saving model ...\n",
            "Epoch: 61 \tTraining Loss: 607.6661 \tTraining Accuracy: 10.7235 \tValidation Loss: 707.4347 \tValidation Accuracy: 11.1180 \ttrain_kl_div: 2709.1060\n",
            "Validation loss decreased (733.430415 --> 707.434686).  Saving model ...\n",
            "Epoch: 62 \tTraining Loss: 604.4696 \tTraining Accuracy: 10.8108 \tValidation Loss: 690.4483 \tValidation Accuracy: 10.8140 \ttrain_kl_div: 2275.5316\n",
            "Validation loss decreased (707.434686 --> 690.448258).  Saving model ...\n",
            "Epoch: 63 \tTraining Loss: 602.2855 \tTraining Accuracy: 10.8045 \tValidation Loss: 677.8868 \tValidation Accuracy: 11.0764 \ttrain_kl_div: 1979.7879\n",
            "Validation loss decreased (690.448258 --> 677.886776).  Saving model ...\n",
            "Epoch: 64 \tTraining Loss: 600.9003 \tTraining Accuracy: 10.7110 \tValidation Loss: 669.8191 \tValidation Accuracy: 11.1429 \ttrain_kl_div: 1771.5780\n",
            "Validation loss decreased (677.886776 --> 669.819140).  Saving model ...\n",
            "Epoch: 65 \tTraining Loss: 599.8385 \tTraining Accuracy: 10.8128 \tValidation Loss: 662.7714 \tValidation Accuracy: 11.1548 \ttrain_kl_div: 1616.1216\n",
            "Validation loss decreased (669.819140 --> 662.771390).  Saving model ...\n",
            "Epoch: 66 \tTraining Loss: 599.0698 \tTraining Accuracy: 10.6819 \tValidation Loss: 658.7746 \tValidation Accuracy: 11.0824 \ttrain_kl_div: 1491.7916\n",
            "Validation loss decreased (662.771390 --> 658.774606).  Saving model ...\n",
            "Epoch: 67 \tTraining Loss: 598.4624 \tTraining Accuracy: 10.7630 \tValidation Loss: 653.0934 \tValidation Accuracy: 11.0491 \ttrain_kl_div: 1381.3596\n",
            "Validation loss decreased (658.774606 --> 653.093385).  Saving model ...\n",
            "Epoch: 68 \tTraining Loss: 597.7277 \tTraining Accuracy: 10.9001 \tValidation Loss: 649.2127 \tValidation Accuracy: 10.9090 \ttrain_kl_div: 1283.5406\n",
            "Validation loss decreased (653.093385 --> 649.212657).  Saving model ...\n",
            "Epoch: 69 \tTraining Loss: 597.2494 \tTraining Accuracy: 10.7027 \tValidation Loss: 646.3787 \tValidation Accuracy: 11.1441 \ttrain_kl_div: 1202.5303\n",
            "Validation loss decreased (649.212657 --> 646.378682).  Saving model ...\n",
            "Epoch: 70 \tTraining Loss: 597.0028 \tTraining Accuracy: 10.6736 \tValidation Loss: 643.6880 \tValidation Accuracy: 11.0242 \ttrain_kl_div: 1148.4577\n",
            "Validation loss decreased (646.378682 --> 643.688043).  Saving model ...\n",
            "Epoch: 71 \tTraining Loss: 596.5995 \tTraining Accuracy: 10.8128 \tValidation Loss: 641.0518 \tValidation Accuracy: 10.8413 \ttrain_kl_div: 1069.2314\n",
            "Validation loss decreased (643.688043 --> 641.051777).  Saving model ...\n",
            "Epoch: 72 \tTraining Loss: 596.3397 \tTraining Accuracy: 10.6383 \tValidation Loss: 639.0403 \tValidation Accuracy: 10.3118 \ttrain_kl_div: 1020.6399\n",
            "Validation loss decreased (641.051777 --> 639.040342).  Saving model ...\n",
            "Epoch: 73 \tTraining Loss: 596.0082 \tTraining Accuracy: 10.5386 \tValidation Loss: 636.3390 \tValidation Accuracy: 11.3139 \ttrain_kl_div: 962.6859\n",
            "Validation loss decreased (639.040342 --> 636.338952).  Saving model ...\n",
            "Epoch: 74 \tTraining Loss: 595.5849 \tTraining Accuracy: 10.7256 \tValidation Loss: 633.6234 \tValidation Accuracy: 11.0135 \ttrain_kl_div: 894.9876\n",
            "Validation loss decreased (636.338952 --> 633.623381).  Saving model ...\n",
            "Epoch: 75 \tTraining Loss: 595.4014 \tTraining Accuracy: 10.8502 \tValidation Loss: 633.1208 \tValidation Accuracy: 11.1975 \ttrain_kl_div: 871.7360\n",
            "Validation loss decreased (633.623381 --> 633.120848).  Saving model ...\n",
            "Epoch: 76 \tTraining Loss: 595.1612 \tTraining Accuracy: 10.6279 \tValidation Loss: 630.3524 \tValidation Accuracy: 10.5326 \ttrain_kl_div: 824.6188\n",
            "Validation loss decreased (633.120848 --> 630.352399).  Saving model ...\n",
            "Epoch: 77 \tTraining Loss: 594.8488 \tTraining Accuracy: 10.7422 \tValidation Loss: 628.9787 \tValidation Accuracy: 10.9921 \ttrain_kl_div: 783.4114\n",
            "Validation loss decreased (630.352399 --> 628.978743).  Saving model ...\n",
            "Epoch: 78 \tTraining Loss: 594.7261 \tTraining Accuracy: 10.7006 \tValidation Loss: 627.3319 \tValidation Accuracy: 10.6763 \ttrain_kl_div: 766.6049\n",
            "Validation loss decreased (628.978743 --> 627.331875).  Saving model ...\n",
            "Epoch: 79 \tTraining Loss: 594.4629 \tTraining Accuracy: 10.6487 \tValidation Loss: 625.9684 \tValidation Accuracy: 11.0669 \ttrain_kl_div: 736.5945\n",
            "Validation loss decreased (627.331875 --> 625.968406).  Saving model ...\n",
            "Epoch: 80 \tTraining Loss: 594.3658 \tTraining Accuracy: 10.7339 \tValidation Loss: 625.8139 \tValidation Accuracy: 11.0064 \ttrain_kl_div: 742.8601\n",
            "Validation loss decreased (625.968406 --> 625.813939).  Saving model ...\n",
            "Epoch: 81 \tTraining Loss: 594.2743 \tTraining Accuracy: 10.8004 \tValidation Loss: 625.9963 \tValidation Accuracy: 10.8390 \ttrain_kl_div: 740.0427\n",
            "Epoch: 82 \tTraining Loss: 594.2858 \tTraining Accuracy: 10.7983 \tValidation Loss: 625.7671 \tValidation Accuracy: 10.7867 \ttrain_kl_div: 739.7394\n",
            "Validation loss decreased (625.813939 --> 625.767091).  Saving model ...\n",
            "Epoch: 83 \tTraining Loss: 594.2268 \tTraining Accuracy: 10.8565 \tValidation Loss: 626.0548 \tValidation Accuracy: 11.0669 \ttrain_kl_div: 751.5279\n",
            "Epoch: 84 \tTraining Loss: 594.2022 \tTraining Accuracy: 10.7858 \tValidation Loss: 628.1933 \tValidation Accuracy: 10.8271 \ttrain_kl_div: 801.7041\n",
            "Epoch: 85 \tTraining Loss: 594.4678 \tTraining Accuracy: 10.7671 \tValidation Loss: 629.6028 \tValidation Accuracy: 10.9589 \ttrain_kl_div: 814.0038\n",
            "Epoch: 86 \tTraining Loss: 594.4713 \tTraining Accuracy: 10.5593 \tValidation Loss: 630.1409 \tValidation Accuracy: 10.8781 \ttrain_kl_div: 838.6748\n",
            "Epoch 00088: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 87 \tTraining Loss: 594.5584 \tTraining Accuracy: 10.7650 \tValidation Loss: 632.0946 \tValidation Accuracy: 10.8912 \ttrain_kl_div: 867.7091\n",
            "Epoch: 88 \tTraining Loss: 594.9128 \tTraining Accuracy: 10.8149 \tValidation Loss: 625.3314 \tValidation Accuracy: 10.7665 \ttrain_kl_div: 849.0100\n",
            "Validation loss decreased (625.767091 --> 625.331405).  Saving model ...\n",
            "Epoch: 89 \tTraining Loss: 594.0107 \tTraining Accuracy: 10.8211 \tValidation Loss: 621.6214 \tValidation Accuracy: 10.5148 \ttrain_kl_div: 747.0963\n",
            "Validation loss decreased (625.331405 --> 621.621421).  Saving model ...\n",
            "Epoch: 90 \tTraining Loss: 593.5155 \tTraining Accuracy: 10.7484 \tValidation Loss: 618.7306 \tValidation Accuracy: 10.7440 \ttrain_kl_div: 677.9067\n",
            "Validation loss decreased (621.621421 --> 618.730641).  Saving model ...\n",
            "Epoch: 91 \tTraining Loss: 593.2290 \tTraining Accuracy: 10.9624 \tValidation Loss: 616.8765 \tValidation Accuracy: 10.9102 \ttrain_kl_div: 631.9713\n",
            "Validation loss decreased (618.730641 --> 616.876517).  Saving model ...\n",
            "Epoch: 92 \tTraining Loss: 593.1083 \tTraining Accuracy: 10.7276 \tValidation Loss: 615.7428 \tValidation Accuracy: 10.4780 \ttrain_kl_div: 600.8639\n",
            "Validation loss decreased (616.876517 --> 615.742755).  Saving model ...\n",
            "Epoch: 93 \tTraining Loss: 593.0175 \tTraining Accuracy: 10.6840 \tValidation Loss: 615.0075 \tValidation Accuracy: 10.9399 \ttrain_kl_div: 581.1432\n",
            "Validation loss decreased (615.742755 --> 615.007450).  Saving model ...\n",
            "Epoch: 94 \tTraining Loss: 592.7109 \tTraining Accuracy: 11.0123 \tValidation Loss: 614.3729 \tValidation Accuracy: 10.6347 \ttrain_kl_div: 565.8357\n",
            "Validation loss decreased (615.007450 --> 614.372860).  Saving model ...\n",
            "Epoch: 95 \tTraining Loss: 592.8018 \tTraining Accuracy: 11.0227 \tValidation Loss: 614.1624 \tValidation Accuracy: 10.7321 \ttrain_kl_div: 555.7091\n",
            "Validation loss decreased (614.372860 --> 614.162392).  Saving model ...\n",
            "Epoch: 96 \tTraining Loss: 592.7958 \tTraining Accuracy: 10.8710 \tValidation Loss: 614.1847 \tValidation Accuracy: 10.6027 \ttrain_kl_div: 551.8480\n",
            "Epoch: 97 \tTraining Loss: 593.0139 \tTraining Accuracy: 10.8523 \tValidation Loss: 614.0498 \tValidation Accuracy: 11.1524 \ttrain_kl_div: 551.1034\n",
            "Validation loss decreased (614.162392 --> 614.049772).  Saving model ...\n",
            "Epoch: 98 \tTraining Loss: 592.7921 \tTraining Accuracy: 10.9209 \tValidation Loss: 613.9133 \tValidation Accuracy: 10.9719 \ttrain_kl_div: 548.0314\n",
            "Validation loss decreased (614.049772 --> 613.913314).  Saving model ...\n",
            "Epoch: 99 \tTraining Loss: 592.7489 \tTraining Accuracy: 10.8939 \tValidation Loss: 614.0823 \tValidation Accuracy: 10.4543 \ttrain_kl_div: 543.0916\n"
          ]
        }
      ],
      "source": [
        "!python main_bayesian.py --net_type lenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCxlvoUWw2KT"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-abbcTDHwul",
        "outputId": "66345269-241f-4056-b739-fac7d4c9030e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-08 04:09:58.375599: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-08 04:09:59.279819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parameters initialized\n",
            "188it [00:15, 12.33it/s]\n",
            "Epoch: 0 \tTraining Loss: 2362160.1339 \tTraining Accuracy: 10.6632 \tValidation Loss: 10395704.6545 \tValidation Accuracy: 13.3038 \ttrain_kl_div: 252109019.4043\n",
            "Validation loss decreased (inf --> 10395704.654475).  Saving model ...\n",
            "188it [00:14, 12.62it/s]\n",
            "Epoch: 1 \tTraining Loss: 1239651.5968 \tTraining Accuracy: 11.3759 \tValidation Loss: 9175786.2675 \tValidation Accuracy: 12.0785 \ttrain_kl_div: 213232582.4681\n",
            "Validation loss decreased (10395704.654475 --> 9175786.267521).  Saving model ...\n",
            "188it [00:14, 13.25it/s]\n",
            "Epoch: 2 \tTraining Loss: 1052211.9970 \tTraining Accuracy: 30.5623 \tValidation Loss: 7903584.7766 \tValidation Accuracy: 69.9041 \ttrain_kl_div: 181074742.8085\n",
            "Validation loss decreased (9175786.267521 --> 7903584.776616).  Saving model ...\n",
            "188it [00:14, 13.11it/s]\n",
            "Epoch: 3 \tTraining Loss: 902907.3463 \tTraining Accuracy: 33.7060 \tValidation Loss: 5172929.9264 \tValidation Accuracy: 74.5975 \ttrain_kl_div: 120313798.7234\n",
            "Validation loss decreased (7903584.776616 --> 5172929.926421).  Saving model ...\n",
            "188it [00:14, 13.21it/s]\n",
            "Epoch: 4 \tTraining Loss: 608924.6461 \tTraining Accuracy: 11.9369 \tValidation Loss: 3553482.0295 \tValidation Accuracy: 12.8396 \ttrain_kl_div: 83649664.5532\n",
            "Validation loss decreased (5172929.926421 --> 3553482.029544).  Saving model ...\n",
            "188it [00:15, 12.50it/s]\n",
            "Epoch: 5 \tTraining Loss: 429048.8831 \tTraining Accuracy: 10.3038 \tValidation Loss: 2758291.7560 \tValidation Accuracy: 10.5706 \ttrain_kl_div: 65118932.3404\n",
            "Validation loss decreased (3553482.029544 --> 2758291.755968).  Saving model ...\n",
            "188it [00:14, 13.02it/s]\n",
            "Epoch: 6 \tTraining Loss: 337509.2579 \tTraining Accuracy: 10.2892 \tValidation Loss: 2266474.1926 \tValidation Accuracy: 10.2975 \ttrain_kl_div: 53590546.5957\n",
            "Validation loss decreased (2758291.755968 --> 2266474.192613).  Saving model ...\n",
            "188it [00:14, 13.15it/s]\n",
            "Epoch: 7 \tTraining Loss: 279257.2844 \tTraining Accuracy: 10.1168 \tValidation Loss: 1912421.0035 \tValidation Accuracy: 10.3996 \ttrain_kl_div: 45258141.4894\n",
            "Validation loss decreased (2266474.192613 --> 1912421.003492).  Saving model ...\n",
            "188it [00:14, 12.64it/s]\n",
            "Epoch: 8 \tTraining Loss: 236545.9637 \tTraining Accuracy: 10.3183 \tValidation Loss: 1636596.4836 \tValidation Accuracy: 10.6490 \ttrain_kl_div: 38747017.5745\n",
            "Validation loss decreased (1912421.003492 --> 1636596.483641).  Saving model ...\n",
            "188it [00:14, 13.29it/s]\n",
            "Epoch: 9 \tTraining Loss: 202911.6481 \tTraining Accuracy: 10.3661 \tValidation Loss: 1412605.5615 \tValidation Accuracy: 10.3937 \ttrain_kl_div: 33449469.6702\n",
            "Validation loss decreased (1636596.483641 --> 1412605.561544).  Saving model ...\n",
            "188it [00:14, 13.01it/s]\n",
            "Epoch: 10 \tTraining Loss: 175418.0339 \tTraining Accuracy: 10.1562 \tValidation Loss: 1226136.1292 \tValidation Accuracy: 10.5694 \ttrain_kl_div: 29034242.6383\n",
            "Validation loss decreased (1412605.561544 --> 1226136.129180).  Saving model ...\n",
            "188it [00:14, 13.23it/s]\n",
            "Epoch: 11 \tTraining Loss: 152443.0984 \tTraining Accuracy: 10.1874 \tValidation Loss: 1068565.4814 \tValidation Accuracy: 10.7000 \ttrain_kl_div: 25301110.3191\n",
            "Validation loss decreased (1226136.129180 --> 1068565.481374).  Saving model ...\n",
            "188it [00:14, 13.10it/s]\n",
            "Epoch: 12 \tTraining Loss: 132980.0996 \tTraining Accuracy: 10.3703 \tValidation Loss: 933996.2202 \tValidation Accuracy: 10.0791 \ttrain_kl_div: 22111931.3936\n",
            "Validation loss decreased (1068565.481374 --> 933996.220206).  Saving model ...\n",
            "188it [00:14, 12.74it/s]\n",
            "Epoch: 13 \tTraining Loss: 116333.3833 \tTraining Accuracy: 10.3246 \tValidation Loss: 818281.6184 \tValidation Accuracy: 10.4163 \ttrain_kl_div: 19369342.3085\n",
            "Validation loss decreased (933996.220206 --> 818281.618368).  Saving model ...\n",
            "188it [00:14, 13.21it/s]\n",
            "Epoch: 14 \tTraining Loss: 102002.7456 \tTraining Accuracy: 10.3329 \tValidation Loss: 718131.5512 \tValidation Accuracy: 10.8378 \ttrain_kl_div: 16995671.4149\n",
            "Validation loss decreased (818281.618368 --> 718131.551153).  Saving model ...\n",
            "188it [00:14, 13.17it/s]\n",
            "Epoch: 15 \tTraining Loss: 89592.5396 \tTraining Accuracy: 10.2165 \tValidation Loss: 631034.6612 \tValidation Accuracy: 10.3438 \ttrain_kl_div: 14931604.8989\n",
            "Validation loss decreased (718131.551153 --> 631034.661160).  Saving model ...\n",
            "188it [00:14, 13.07it/s]\n",
            "Epoch: 16 \tTraining Loss: 78794.9199 \tTraining Accuracy: 10.1895 \tValidation Loss: 554991.2671 \tValidation Accuracy: 10.7143 \ttrain_kl_div: 13129889.8989\n",
            "Validation loss decreased (631034.661160 --> 554991.267104).  Saving model ...\n",
            "188it [00:14, 13.20it/s]\n",
            "Epoch: 17 \tTraining Loss: 69365.5930 \tTraining Accuracy: 10.3308 \tValidation Loss: 488409.3734 \tValidation Accuracy: 10.4044 \ttrain_kl_div: 11552575.9840\n",
            "Validation loss decreased (554991.267104 --> 488409.373396).  Saving model ...\n",
            "188it [00:15, 12.40it/s]\n",
            "Epoch: 18 \tTraining Loss: 61107.5009 \tTraining Accuracy: 10.0835 \tValidation Loss: 429959.1279 \tValidation Accuracy: 10.7547 \ttrain_kl_div: 10168072.1755\n",
            "Validation loss decreased (488409.373396 --> 429959.127921).  Saving model ...\n",
            "188it [00:14, 13.24it/s]\n",
            "Epoch: 19 \tTraining Loss: 53856.8642 \tTraining Accuracy: 10.2331 \tValidation Loss: 378527.8493 \tValidation Accuracy: 10.9458 \ttrain_kl_div: 8950039.1862\n",
            "Validation loss decreased (429959.127921 --> 378527.849268).  Saving model ...\n",
            "188it [00:14, 13.19it/s]\n",
            "Epoch: 20 \tTraining Loss: 47476.6506 \tTraining Accuracy: 10.2227 \tValidation Loss: 333199.6473 \tValidation Accuracy: 11.1097 \ttrain_kl_div: 7876622.8218\n",
            "Validation loss decreased (378527.849268 --> 333199.647336).  Saving model ...\n",
            "188it [00:14, 13.14it/s]\n",
            "Epoch: 21 \tTraining Loss: 41852.5922 \tTraining Accuracy: 10.1957 \tValidation Loss: 293178.0746 \tValidation Accuracy: 11.2296 \ttrain_kl_div: 6928985.0798\n",
            "Validation loss decreased (333199.647336 --> 293178.074633).  Saving model ...\n",
            "188it [00:14, 13.10it/s]\n",
            "Epoch: 22 \tTraining Loss: 36886.2432 \tTraining Accuracy: 10.5116 \tValidation Loss: 257797.0649 \tValidation Accuracy: 11.3210 \ttrain_kl_div: 6091284.1569\n",
            "Validation loss decreased (293178.074633 --> 257797.064887).  Saving model ...\n",
            "188it [00:15, 12.16it/s]\n",
            "Epoch: 23 \tTraining Loss: 32495.6247 \tTraining Accuracy: 10.5614 \tValidation Loss: 226494.5276 \tValidation Accuracy: 11.1809 \ttrain_kl_div: 5350190.6835\n",
            "Validation loss decreased (257797.064887 --> 226494.527619).  Saving model ...\n",
            "188it [00:14, 13.30it/s]\n",
            "Epoch: 24 \tTraining Loss: 28611.4566 \tTraining Accuracy: 10.4908 \tValidation Loss: 198784.8875 \tValidation Accuracy: 11.4219 \ttrain_kl_div: 4694214.6383\n",
            "Validation loss decreased (226494.527619 --> 198784.887517).  Saving model ...\n",
            "188it [00:14, 12.98it/s]\n",
            "Epoch: 25 \tTraining Loss: 25172.2550 \tTraining Accuracy: 10.4679 \tValidation Loss: 174233.4026 \tValidation Accuracy: 10.8211 \ttrain_kl_div: 4113014.3763\n",
            "Validation loss decreased (198784.887517 --> 174233.402579).  Saving model ...\n",
            "188it [00:14, 12.95it/s]\n",
            "Epoch: 26 \tTraining Loss: 22125.2427 \tTraining Accuracy: 10.6445 \tValidation Loss: 152483.1646 \tValidation Accuracy: 11.0004 \ttrain_kl_div: 3598130.4920\n",
            "Validation loss decreased (174233.402579 --> 152483.164618).  Saving model ...\n",
            "188it [00:14, 12.88it/s]\n",
            "Epoch: 27 \tTraining Loss: 19425.9762 \tTraining Accuracy: 10.4139 \tValidation Loss: 133222.3926 \tValidation Accuracy: 10.4709 \ttrain_kl_div: 3142145.2660\n",
            "Validation loss decreased (152483.164618 --> 133222.392647).  Saving model ...\n",
            "188it [00:15, 12.47it/s]\n",
            "Epoch: 28 \tTraining Loss: 17035.5772 \tTraining Accuracy: 10.3703 \tValidation Loss: 116166.7939 \tValidation Accuracy: 10.6181 \ttrain_kl_div: 2738408.7926\n",
            "Validation loss decreased (133222.392647 --> 116166.793860).  Saving model ...\n",
            "188it [00:14, 13.23it/s]\n",
            "Epoch: 29 \tTraining Loss: 14918.9829 \tTraining Accuracy: 10.2643 \tValidation Loss: 101076.5257 \tValidation Accuracy: 11.4955 \ttrain_kl_div: 2381081.2753\n",
            "Validation loss decreased (116166.793860 --> 101076.525656).  Saving model ...\n",
            "188it [00:14, 12.76it/s]\n",
            "Epoch: 30 \tTraining Loss: 13046.2782 \tTraining Accuracy: 10.5967 \tValidation Loss: 87736.6083 \tValidation Accuracy: 10.5908 \ttrain_kl_div: 2065268.7806\n",
            "Validation loss decreased (101076.525656 --> 87736.608330).  Saving model ...\n",
            "188it [00:14, 13.23it/s]\n",
            "Epoch: 31 \tTraining Loss: 11390.7857 \tTraining Accuracy: 10.8565 \tValidation Loss: 75976.2030 \tValidation Accuracy: 11.1821 \ttrain_kl_div: 1786736.7779\n",
            "Validation loss decreased (87736.608330 --> 75976.203002).  Saving model ...\n",
            "188it [00:14, 13.16it/s]\n",
            "Epoch: 32 \tTraining Loss: 9931.1568 \tTraining Accuracy: 10.4929 \tValidation Loss: 65592.9223 \tValidation Accuracy: 11.2225 \ttrain_kl_div: 1540841.8657\n",
            "Validation loss decreased (75976.203002 --> 65592.922258).  Saving model ...\n",
            "188it [00:14, 12.67it/s]\n",
            "Epoch: 33 \tTraining Loss: 8642.8543 \tTraining Accuracy: 10.7692 \tValidation Loss: 56483.0508 \tValidation Accuracy: 10.5896 \ttrain_kl_div: 1324972.7241\n",
            "Validation loss decreased (65592.922258 --> 56483.050794).  Saving model ...\n",
            "188it [00:14, 13.27it/s]\n",
            "Epoch: 34 \tTraining Loss: 7511.5544 \tTraining Accuracy: 10.5864 \tValidation Loss: 48457.1514 \tValidation Accuracy: 10.5433 \ttrain_kl_div: 1134911.3803\n",
            "Validation loss decreased (56483.050794 --> 48457.151430).  Saving model ...\n",
            "188it [00:14, 12.95it/s]\n",
            "Epoch: 35 \tTraining Loss: 6515.9381 \tTraining Accuracy: 10.7692 \tValidation Loss: 41473.8345 \tValidation Accuracy: 11.2260 \ttrain_kl_div: 969305.7999\n",
            "Validation loss decreased (48457.151430 --> 41473.834540).  Saving model ...\n",
            "188it [00:14, 13.18it/s]\n",
            "Epoch: 36 \tTraining Loss: 5649.1721 \tTraining Accuracy: 10.5801 \tValidation Loss: 35361.9715 \tValidation Accuracy: 11.2213 \ttrain_kl_div: 824418.5233\n",
            "Validation loss decreased (41473.834540 --> 35361.971528).  Saving model ...\n",
            "188it [00:14, 12.85it/s]\n",
            "Epoch: 37 \tTraining Loss: 4889.6065 \tTraining Accuracy: 10.8939 \tValidation Loss: 30001.9202 \tValidation Accuracy: 11.1880 \ttrain_kl_div: 697457.7776\n",
            "Validation loss decreased (35361.971528 --> 30001.920209).  Saving model ...\n",
            "188it [00:15, 12.49it/s]\n",
            "Epoch: 38 \tTraining Loss: 4225.4753 \tTraining Accuracy: 10.6819 \tValidation Loss: 25456.8203 \tValidation Accuracy: 11.5561 \ttrain_kl_div: 589428.1529\n",
            "Validation loss decreased (30001.920209 --> 25456.820298).  Saving model ...\n",
            "188it [00:14, 12.62it/s]\n",
            "Epoch: 39 \tTraining Loss: 3660.2613 \tTraining Accuracy: 10.5469 \tValidation Loss: 21535.8070 \tValidation Accuracy: 10.7986 \ttrain_kl_div: 496216.0479\n",
            "Validation loss decreased (25456.820298 --> 21535.807035).  Saving model ...\n",
            "188it [00:15, 12.32it/s]\n",
            "Epoch: 40 \tTraining Loss: 3171.9486 \tTraining Accuracy: 10.8939 \tValidation Loss: 18198.6246 \tValidation Accuracy: 10.8271 \ttrain_kl_div: 416745.8567\n",
            "Validation loss decreased (21535.807035 --> 18198.624620).  Saving model ...\n",
            "188it [00:14, 13.27it/s]\n",
            "Epoch: 41 \tTraining Loss: 2756.1034 \tTraining Accuracy: 10.7983 \tValidation Loss: 15371.8915 \tValidation Accuracy: 11.2854 \ttrain_kl_div: 349319.4277\n",
            "Validation loss decreased (18198.624620 --> 15371.891456).  Saving model ...\n",
            "188it [00:14, 12.55it/s]\n",
            "Epoch: 42 \tTraining Loss: 2402.6656 \tTraining Accuracy: 10.5573 \tValidation Loss: 13007.8051 \tValidation Accuracy: 11.1999 \ttrain_kl_div: 292874.1024\n",
            "Validation loss decreased (15371.891456 --> 13007.805082).  Saving model ...\n",
            "188it [00:14, 12.79it/s]\n",
            "Epoch: 43 \tTraining Loss: 2105.8226 \tTraining Accuracy: 10.5406 \tValidation Loss: 11100.0860 \tValidation Accuracy: 11.3020 \ttrain_kl_div: 246822.9031\n",
            "Validation loss decreased (13007.805082 --> 11100.086040).  Saving model ...\n",
            "188it [00:14, 12.76it/s]\n",
            "Epoch: 44 \tTraining Loss: 1865.1938 \tTraining Accuracy: 10.8232 \tValidation Loss: 9619.6151 \tValidation Accuracy: 11.1334 \ttrain_kl_div: 210617.9339\n",
            "Validation loss decreased (11100.086040 --> 9619.615075).  Saving model ...\n",
            "188it [00:15, 12.14it/s]\n",
            "Epoch: 45 \tTraining Loss: 1675.4608 \tTraining Accuracy: 10.8856 \tValidation Loss: 8425.6654 \tValidation Accuracy: 10.7725 \ttrain_kl_div: 181248.4212\n",
            "Validation loss decreased (9619.615075 --> 8425.665433).  Saving model ...\n",
            "188it [00:14, 13.12it/s]\n",
            "Epoch: 46 \tTraining Loss: 1520.2808 \tTraining Accuracy: 10.7775 \tValidation Loss: 7458.4691 \tValidation Accuracy: 11.4587 \ttrain_kl_div: 157450.5631\n",
            "Validation loss decreased (8425.665433 --> 7458.469075).  Saving model ...\n",
            "188it [00:15, 12.53it/s]\n",
            "Epoch: 47 \tTraining Loss: 1393.4749 \tTraining Accuracy: 10.8772 \tValidation Loss: 6324.7785 \tValidation Accuracy: 11.1785 \ttrain_kl_div: 131248.2643\n",
            "Validation loss decreased (7458.469075 --> 6324.778454).  Saving model ...\n",
            "188it [00:14, 12.98it/s]\n",
            "Epoch: 48 \tTraining Loss: 1251.9608 \tTraining Accuracy: 10.8419 \tValidation Loss: 5983.6490 \tValidation Accuracy: 10.9565 \ttrain_kl_div: 122016.7533\n",
            "Validation loss decreased (6324.778454 --> 5983.649047).  Saving model ...\n",
            "188it [00:14, 12.88it/s]\n",
            "Epoch: 49 \tTraining Loss: 1194.2133 \tTraining Accuracy: 10.7006 \tValidation Loss: 6689.0631 \tValidation Accuracy: 10.7202 \ttrain_kl_div: 134954.9326\n",
            "188it [00:14, 12.85it/s]\n",
            "Epoch: 50 \tTraining Loss: 1241.9264 \tTraining Accuracy: 10.7983 \tValidation Loss: 8197.3245 \tValidation Accuracy: 11.4670 \ttrain_kl_div: 165749.1158\n",
            "188it [00:14, 12.99it/s]\n",
            "Epoch: 51 \tTraining Loss: 1374.9015 \tTraining Accuracy: 10.8980 \tValidation Loss: 12131.1048 \tValidation Accuracy: 11.2878 \ttrain_kl_div: 247622.9296\n",
            "188it [00:15, 12.32it/s]\n",
            "Epoch: 52 \tTraining Loss: 1755.7095 \tTraining Accuracy: 10.8461 \tValidation Loss: 16073.9054 \tValidation Accuracy: 11.4670 \ttrain_kl_div: 330228.4865\n",
            "188it [00:14, 12.85it/s]\n",
            "Epoch: 53 \tTraining Loss: 2149.2859 \tTraining Accuracy: 10.7256 \tValidation Loss: 21758.8977 \tValidation Accuracy: 10.7297 \ttrain_kl_div: 447735.3472\n",
            "188it [00:14, 12.77it/s]\n",
            "Epoch: 54 \tTraining Loss: 2701.1389 \tTraining Accuracy: 10.9209 \tValidation Loss: 29844.0474 \tValidation Accuracy: 11.0313 \ttrain_kl_div: 622605.4929\n",
            "188it [00:14, 12.89it/s]\n",
            "Epoch 00056: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch: 55 \tTraining Loss: 3527.7120 \tTraining Accuracy: 10.7630 \tValidation Loss: 30696.1064 \tValidation Accuracy: 11.3020 \ttrain_kl_div: 644351.1090\n",
            "188it [00:14, 12.90it/s]\n",
            "Epoch: 56 \tTraining Loss: 4253.4877 \tTraining Accuracy: 10.9604 \tValidation Loss: 19348.5678 \tValidation Accuracy: 11.3827 \ttrain_kl_div: 455316.6611\n",
            "188it [00:15, 12.03it/s]\n",
            "Epoch: 57 \tTraining Loss: 2881.3414 \tTraining Accuracy: 10.9417 \tValidation Loss: 13157.8211 \tValidation Accuracy: 11.2070 \ttrain_kl_div: 303333.8366\n",
            "188it [00:14, 12.86it/s]\n",
            "Epoch: 58 \tTraining Loss: 2129.1012 \tTraining Accuracy: 10.9998 \tValidation Loss: 9442.2386 \tValidation Accuracy: 11.3863 \ttrain_kl_div: 212848.4146\n",
            "188it [00:15, 12.52it/s]\n",
            "Epoch: 59 \tTraining Loss: 1676.4047 \tTraining Accuracy: 10.9832 \tValidation Loss: 7103.2916 \tValidation Accuracy: 11.3020 \ttrain_kl_div: 156088.1388\n",
            "188it [00:14, 12.82it/s]\n",
            "Epoch: 60 \tTraining Loss: 1391.1343 \tTraining Accuracy: 11.0871 \tValidation Loss: 5583.4402 \tValidation Accuracy: 11.1963 \ttrain_kl_div: 119310.0837\n",
            "Validation loss decreased (5983.649047 --> 5583.440152).  Saving model ...\n",
            "188it [00:14, 12.92it/s]\n",
            "Epoch: 61 \tTraining Loss: 1205.5842 \tTraining Accuracy: 10.9230 \tValidation Loss: 4571.1404 \tValidation Accuracy: 11.3352 \ttrain_kl_div: 94823.5376\n",
            "Validation loss decreased (5583.440152 --> 4571.140416).  Saving model ...\n",
            "188it [00:14, 12.74it/s]\n",
            "Epoch: 62 \tTraining Loss: 1081.6989 \tTraining Accuracy: 10.9167 \tValidation Loss: 3877.0610 \tValidation Accuracy: 11.3400 \ttrain_kl_div: 78097.4088\n",
            "Validation loss decreased (4571.140416 --> 3877.061001).  Saving model ...\n",
            "188it [00:14, 12.80it/s]\n",
            "Epoch: 63 \tTraining Loss: 997.0361 \tTraining Accuracy: 11.0850 \tValidation Loss: 3386.9090 \tValidation Accuracy: 11.3459 \ttrain_kl_div: 66286.4812\n",
            "Validation loss decreased (3877.061001 --> 3386.908977).  Saving model ...\n",
            "188it [00:15, 11.88it/s]\n",
            "Epoch: 64 \tTraining Loss: 936.9021 \tTraining Accuracy: 10.8959 \tValidation Loss: 3026.2667 \tValidation Accuracy: 11.3436 \ttrain_kl_div: 57656.1885\n",
            "Validation loss decreased (3386.908977 --> 3026.266657).  Saving model ...\n",
            "188it [00:14, 12.76it/s]\n",
            "Epoch: 65 \tTraining Loss: 892.6584 \tTraining Accuracy: 10.9313 \tValidation Loss: 2750.8846 \tValidation Accuracy: 11.0942 \ttrain_kl_div: 51057.6572\n",
            "Validation loss decreased (3026.266657 --> 2750.884619).  Saving model ...\n",
            "188it [00:14, 12.83it/s]\n",
            "Epoch: 66 \tTraining Loss: 858.0896 \tTraining Accuracy: 10.7214 \tValidation Loss: 2524.1519 \tValidation Accuracy: 11.3661 \ttrain_kl_div: 45711.3308\n",
            "Validation loss decreased (2750.884619 --> 2524.151918).  Saving model ...\n",
            "188it [00:14, 12.77it/s]\n",
            "Epoch: 67 \tTraining Loss: 830.2291 \tTraining Accuracy: 11.0663 \tValidation Loss: 2331.9642 \tValidation Accuracy: 11.1655 \ttrain_kl_div: 41142.1963\n",
            "Validation loss decreased (2524.151918 --> 2331.964239).  Saving model ...\n",
            "188it [00:14, 12.92it/s]\n",
            "Epoch: 68 \tTraining Loss: 806.2302 \tTraining Accuracy: 10.9936 \tValidation Loss: 2160.5426 \tValidation Accuracy: 11.4884 \ttrain_kl_div: 37100.5318\n",
            "Validation loss decreased (2331.964239 --> 2160.542606).  Saving model ...\n",
            "188it [00:15, 12.50it/s]\n",
            "Epoch: 69 \tTraining Loss: 784.9637 \tTraining Accuracy: 11.0061 \tValidation Loss: 2008.7145 \tValidation Accuracy: 11.4100 \ttrain_kl_div: 33478.1169\n",
            "Validation loss decreased (2160.542606 --> 2008.714488).  Saving model ...\n",
            "188it [00:14, 12.83it/s]\n",
            "Epoch: 70 \tTraining Loss: 765.8997 \tTraining Accuracy: 10.9874 \tValidation Loss: 1873.2337 \tValidation Accuracy: 11.3222 \ttrain_kl_div: 30211.2179\n",
            "Validation loss decreased (2008.714488 --> 1873.233728).  Saving model ...\n",
            "188it [00:15, 12.41it/s]\n",
            "Epoch: 71 \tTraining Loss: 749.2584 \tTraining Accuracy: 10.8585 \tValidation Loss: 1746.8242 \tValidation Accuracy: 11.2438 \ttrain_kl_div: 27230.4751\n",
            "Validation loss decreased (1873.233728 --> 1746.824176).  Saving model ...\n",
            "188it [00:14, 12.82it/s]\n",
            "Epoch: 72 \tTraining Loss: 733.8358 \tTraining Accuracy: 11.0165 \tValidation Loss: 1622.1170 \tValidation Accuracy: 10.7986 \ttrain_kl_div: 24273.6537\n",
            "Validation loss decreased (1746.824176 --> 1622.117024).  Saving model ...\n",
            "188it [00:14, 12.81it/s]\n",
            "Epoch: 73 \tTraining Loss: 718.4311 \tTraining Accuracy: 10.9936 \tValidation Loss: 1512.5954 \tValidation Accuracy: 11.1643 \ttrain_kl_div: 21670.9275\n",
            "Validation loss decreased (1622.117024 --> 1512.595423).  Saving model ...\n",
            "188it [00:14, 12.77it/s]\n",
            "Epoch: 74 \tTraining Loss: 704.4123 \tTraining Accuracy: 10.9749 \tValidation Loss: 1414.2380 \tValidation Accuracy: 11.5086 \ttrain_kl_div: 19248.6742\n",
            "Validation loss decreased (1512.595423 --> 1414.237970).  Saving model ...\n",
            "188it [00:14, 12.71it/s]\n",
            "Epoch: 75 \tTraining Loss: 691.8543 \tTraining Accuracy: 11.0871 \tValidation Loss: 1316.1911 \tValidation Accuracy: 11.2331 \ttrain_kl_div: 16969.4911\n",
            "Validation loss decreased (1414.237970 --> 1316.191083).  Saving model ...\n",
            "188it [00:15, 12.34it/s]\n",
            "Epoch: 76 \tTraining Loss: 680.2991 \tTraining Accuracy: 10.9458 \tValidation Loss: 1241.3598 \tValidation Accuracy: 11.1358 \ttrain_kl_div: 15130.7585\n",
            "Validation loss decreased (1316.191083 --> 1241.359783).  Saving model ...\n",
            "188it [00:14, 12.81it/s]\n",
            "Epoch: 77 \tTraining Loss: 670.5660 \tTraining Accuracy: 11.0497 \tValidation Loss: 1191.5259 \tValidation Accuracy: 11.3269 \ttrain_kl_div: 13734.2483\n",
            "Validation loss decreased (1241.359783 --> 1191.525906).  Saving model ...\n",
            "188it [00:14, 12.95it/s]\n",
            "Epoch: 78 \tTraining Loss: 663.5200 \tTraining Accuracy: 10.9791 \tValidation Loss: 1137.2350 \tValidation Accuracy: 11.2272 \ttrain_kl_div: 12620.3229\n",
            "Validation loss decreased (1191.525906 --> 1137.234957).  Saving model ...\n",
            "188it [00:14, 12.76it/s]\n",
            "Epoch: 79 \tTraining Loss: 656.7859 \tTraining Accuracy: 11.1016 \tValidation Loss: 1100.2356 \tValidation Accuracy: 11.4100 \ttrain_kl_div: 11665.9705\n",
            "Validation loss decreased (1137.234957 --> 1100.235623).  Saving model ...\n",
            "188it [00:14, 12.83it/s]\n",
            "Epoch: 80 \tTraining Loss: 651.3896 \tTraining Accuracy: 10.9188 \tValidation Loss: 1095.1047 \tValidation Accuracy: 11.4433 \ttrain_kl_div: 11325.3198\n",
            "Validation loss decreased (1100.235623 --> 1095.104709).  Saving model ...\n",
            "188it [00:14, 12.83it/s]\n",
            "Epoch: 81 \tTraining Loss: 649.7984 \tTraining Accuracy: 10.9458 \tValidation Loss: 1108.7476 \tValidation Accuracy: 11.3091 \ttrain_kl_div: 11703.3091\n",
            "188it [00:14, 12.86it/s]\n",
            "Epoch: 82 \tTraining Loss: 649.0969 \tTraining Accuracy: 11.0684 \tValidation Loss: 1152.4000 \tValidation Accuracy: 11.2842 \ttrain_kl_div: 12430.9912\n",
            "188it [00:15, 12.28it/s]\n",
            "Epoch: 83 \tTraining Loss: 654.8001 \tTraining Accuracy: 11.0123 \tValidation Loss: 1207.5105 \tValidation Accuracy: 11.2616 \ttrain_kl_div: 13498.3685\n",
            "188it [00:14, 12.83it/s]\n",
            "Epoch: 84 \tTraining Loss: 657.5466 \tTraining Accuracy: 10.9417 \tValidation Loss: 1236.4160 \tValidation Accuracy: 10.9434 \ttrain_kl_div: 14017.5441\n",
            "188it [00:14, 12.81it/s]\n",
            "Epoch: 85 \tTraining Loss: 660.6405 \tTraining Accuracy: 11.0913 \tValidation Loss: 1257.1876 \tValidation Accuracy: 10.9375 \ttrain_kl_div: 14475.2866\n",
            "188it [00:14, 12.54it/s]\n",
            "Epoch: 86 \tTraining Loss: 661.9619 \tTraining Accuracy: 10.9230 \tValidation Loss: 1295.0538 \tValidation Accuracy: 11.1999 \ttrain_kl_div: 15269.7308\n",
            "188it [00:14, 12.84it/s]\n",
            "Epoch 00088: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 87 \tTraining Loss: 665.0039 \tTraining Accuracy: 10.8980 \tValidation Loss: 1274.5428 \tValidation Accuracy: 10.9886 \ttrain_kl_div: 14790.0750\n",
            "188it [00:15, 12.31it/s]\n",
            "Epoch: 88 \tTraining Loss: 673.9221 \tTraining Accuracy: 10.9417 \tValidation Loss: 1079.4666 \tValidation Accuracy: 11.2984 \ttrain_kl_div: 11756.5945\n",
            "Validation loss decreased (1095.104709 --> 1079.466632).  Saving model ...\n",
            "188it [00:14, 12.79it/s]\n",
            "Epoch: 89 \tTraining Loss: 650.2915 \tTraining Accuracy: 11.0393 \tValidation Loss: 964.1167 \tValidation Accuracy: 11.2806 \ttrain_kl_div: 8910.9183\n",
            "Validation loss decreased (1079.466632 --> 964.116698).  Saving model ...\n",
            "188it [00:14, 12.67it/s]\n",
            "Epoch: 90 \tTraining Loss: 636.4672 \tTraining Accuracy: 10.8440 \tValidation Loss: 891.4344 \tValidation Accuracy: 11.1607 \ttrain_kl_div: 7131.5508\n",
            "Validation loss decreased (964.116698 --> 891.434390).  Saving model ...\n",
            "188it [00:14, 12.58it/s]\n",
            "Epoch: 91 \tTraining Loss: 627.6137 \tTraining Accuracy: 11.0268 \tValidation Loss: 845.8908 \tValidation Accuracy: 11.1192 \ttrain_kl_div: 6012.1890\n",
            "Validation loss decreased (891.434390 --> 845.890812).  Saving model ...\n",
            "188it [00:15, 12.46it/s]\n",
            "Epoch: 92 \tTraining Loss: 621.8296 \tTraining Accuracy: 10.9728 \tValidation Loss: 815.9260 \tValidation Accuracy: 11.1156 \ttrain_kl_div: 5288.1476\n",
            "Validation loss decreased (845.890812 --> 815.925972).  Saving model ...\n",
            "188it [00:14, 12.71it/s]\n",
            "Epoch: 93 \tTraining Loss: 618.0956 \tTraining Accuracy: 10.9874 \tValidation Loss: 795.7459 \tValidation Accuracy: 11.2201 \ttrain_kl_div: 4811.1925\n",
            "Validation loss decreased (815.925972 --> 795.745900).  Saving model ...\n",
            "188it [00:14, 12.59it/s]\n",
            "Epoch: 94 \tTraining Loss: 615.8921 \tTraining Accuracy: 11.0123 \tValidation Loss: 782.8942 \tValidation Accuracy: 11.0396 \ttrain_kl_div: 4507.6948\n",
            "Validation loss decreased (795.745900 --> 782.894203).  Saving model ...\n",
            "188it [00:15, 12.01it/s]\n",
            "Epoch: 95 \tTraining Loss: 614.3295 \tTraining Accuracy: 10.9209 \tValidation Loss: 774.2390 \tValidation Accuracy: 11.2236 \ttrain_kl_div: 4305.2664\n",
            "Validation loss decreased (782.894203 --> 774.239010).  Saving model ...\n",
            "188it [00:14, 12.69it/s]\n",
            "Epoch: 96 \tTraining Loss: 613.2704 \tTraining Accuracy: 11.0892 \tValidation Loss: 769.1590 \tValidation Accuracy: 11.1275 \ttrain_kl_div: 4163.7508\n",
            "Validation loss decreased (774.239010 --> 769.159006).  Saving model ...\n",
            "188it [00:15, 11.81it/s]\n",
            "Epoch: 97 \tTraining Loss: 612.4623 \tTraining Accuracy: 10.9188 \tValidation Loss: 764.1420 \tValidation Accuracy: 11.1536 \ttrain_kl_div: 4056.1394\n",
            "Validation loss decreased (769.159006 --> 764.141994).  Saving model ...\n",
            "188it [00:14, 12.91it/s]\n",
            "Epoch: 98 \tTraining Loss: 612.1289 \tTraining Accuracy: 11.1037 \tValidation Loss: 762.6181 \tValidation Accuracy: 11.3673 \ttrain_kl_div: 3994.2989\n",
            "Validation loss decreased (764.141994 --> 762.618084).  Saving model ...\n",
            "188it [00:14, 12.92it/s]\n",
            "Epoch: 99 \tTraining Loss: 611.6286 \tTraining Accuracy: 10.8502 \tValidation Loss: 759.0949 \tValidation Accuracy: 11.3258 \ttrain_kl_div: 3929.4394\n",
            "Validation loss decreased (762.618084 --> 759.094938).  Saving model ...\n"
          ]
        }
      ],
      "source": [
        "!python main_bayesian.py --net_type alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QKDy6lkjEVu",
        "outputId": "435a7baa-7934-4abc-c0bb-00a8a1b58a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: 0 \tTraining Loss: 18058.4521 \tTraining Accuracy: 9.8602 \tValidation Loss: 13924.8890 \tValidation Accuracy: 9.4043 \ttrain_kl_div: 237029.6852\n",
            "Validation loss decreased (inf --> 13924.888972).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 2260.7096 \tTraining Accuracy: 9.9448 \tValidation Loss: 12018.4889 \tValidation Accuracy: 9.9023 \ttrain_kl_div: 230127.5222\n",
            "Validation loss decreased (13924.888972 --> 12018.488885).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 2036.2756 \tTraining Accuracy: 9.8651 \tValidation Loss: 11248.5086 \tValidation Accuracy: 9.9121 \ttrain_kl_div: 213921.2504\n",
            "Validation loss decreased (12018.488885 --> 11248.508556).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 1938.2660 \tTraining Accuracy: 10.2981 \tValidation Loss: 10512.8003 \tValidation Accuracy: 10.5469 \ttrain_kl_div: 199192.6721\n",
            "Validation loss decreased (11248.508556 --> 10512.800311).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 1844.9305 \tTraining Accuracy: 9.6537 \tValidation Loss: 9728.7892 \tValidation Accuracy: 9.6484 \ttrain_kl_div: 183594.4518\n",
            "Validation loss decreased (10512.800311 --> 9728.789198).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 1745.0833 \tTraining Accuracy: 9.6014 \tValidation Loss: 8995.5889 \tValidation Accuracy: 9.6777 \ttrain_kl_div: 168859.2095\n",
            "Validation loss decreased (9728.789198 --> 8995.588876).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 1651.1919 \tTraining Accuracy: 9.7109 \tValidation Loss: 8270.7064 \tValidation Accuracy: 9.9023 \ttrain_kl_div: 154266.4488\n",
            "Validation loss decreased (8995.588876 --> 8270.706401).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 1557.2153 \tTraining Accuracy: 9.9522 \tValidation Loss: 7671.2507 \tValidation Accuracy: 10.1270 \ttrain_kl_div: 141926.6584\n",
            "Validation loss decreased (8270.706401 --> 7671.250746).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 1478.2596 \tTraining Accuracy: 9.8726 \tValidation Loss: 7079.8868 \tValidation Accuracy: 10.4004 \ttrain_kl_div: 129742.9912\n",
            "Validation loss decreased (7671.250746 --> 7079.886841).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 1398.5453 \tTraining Accuracy: 9.9149 \tValidation Loss: 6593.4044 \tValidation Accuracy: 10.5371 \ttrain_kl_div: 119593.3409\n",
            "Validation loss decreased (7079.886841 --> 6593.404439).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 1335.7283 \tTraining Accuracy: 10.0070 \tValidation Loss: 5872.4440 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 105357.2269\n",
            "Validation loss decreased (6593.404439 --> 5872.443954).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 1244.1729 \tTraining Accuracy: 10.0294 \tValidation Loss: 5374.1324 \tValidation Accuracy: 9.9609 \ttrain_kl_div: 95184.3416\n",
            "Validation loss decreased (5872.443954 --> 5374.132385).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 1182.6743 \tTraining Accuracy: 9.9920 \tValidation Loss: 4709.5490 \tValidation Accuracy: 9.8926 \ttrain_kl_div: 82194.5573\n",
            "Validation loss decreased (5374.132385 --> 4709.548979).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 1099.5790 \tTraining Accuracy: 9.8502 \tValidation Loss: 4296.0202 \tValidation Accuracy: 9.9316 \ttrain_kl_div: 73720.0731\n",
            "Validation loss decreased (4709.548979 --> 4296.020161).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 1048.2336 \tTraining Accuracy: 9.8229 \tValidation Loss: 3866.1412 \tValidation Accuracy: 10.5176 \ttrain_kl_div: 65131.1631\n",
            "Validation loss decreased (4296.020161 --> 3866.141214).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 992.0745 \tTraining Accuracy: 9.6586 \tValidation Loss: 3742.1486 \tValidation Accuracy: 9.6289 \ttrain_kl_div: 61919.9516\n",
            "Validation loss decreased (3866.141214 --> 3742.148589).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 970.9543 \tTraining Accuracy: 9.8527 \tValidation Loss: 3375.4209 \tValidation Accuracy: 10.0293 \ttrain_kl_div: 54724.2960\n",
            "Validation loss decreased (3742.148589 --> 3375.420929).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 927.7167 \tTraining Accuracy: 10.0717 \tValidation Loss: 2991.9179 \tValidation Accuracy: 10.0977 \ttrain_kl_div: 47303.2197\n",
            "Validation loss decreased (3375.420929 --> 2991.917943).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 880.3508 \tTraining Accuracy: 10.1538 \tValidation Loss: 2761.1704 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 42522.6760\n",
            "Validation loss decreased (2991.917943 --> 2761.170372).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 850.5866 \tTraining Accuracy: 9.9696 \tValidation Loss: 2688.6100 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 40766.7250\n",
            "Validation loss decreased (2761.170372 --> 2688.610030).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 839.1471 \tTraining Accuracy: 10.0567 \tValidation Loss: 2528.0450 \tValidation Accuracy: 9.3945 \ttrain_kl_div: 37357.6720\n",
            "Validation loss decreased (2688.610030 --> 2528.044995).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 816.2760 \tTraining Accuracy: 9.9099 \tValidation Loss: 2397.0308 \tValidation Accuracy: 9.8926 \ttrain_kl_div: 34723.5727\n",
            "Validation loss decreased (2528.044995 --> 2397.030791).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 802.5180 \tTraining Accuracy: 10.2607 \tValidation Loss: 2096.6984 \tValidation Accuracy: 10.3027 \ttrain_kl_div: 29082.5870\n",
            "Validation loss decreased (2397.030791 --> 2096.698384).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 765.5201 \tTraining Accuracy: 9.8353 \tValidation Loss: 2125.6707 \tValidation Accuracy: 10.5176 \ttrain_kl_div: 29269.2471\n",
            "Epoch: 24 \tTraining Loss: 767.6011 \tTraining Accuracy: 9.9124 \tValidation Loss: 1943.7888 \tValidation Accuracy: 9.9609 \ttrain_kl_div: 25801.7853\n",
            "Validation loss decreased (2096.698384 --> 1943.788797).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 745.8188 \tTraining Accuracy: 9.8428 \tValidation Loss: 1893.5024 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 24723.7362\n",
            "Validation loss decreased (1943.788797 --> 1893.502415).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 739.2984 \tTraining Accuracy: 9.7208 \tValidation Loss: 1829.7958 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 23350.5805\n",
            "Validation loss decreased (1893.502415 --> 1829.795833).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 729.8012 \tTraining Accuracy: 10.0020 \tValidation Loss: 1850.6230 \tValidation Accuracy: 10.4492 \ttrain_kl_div: 23563.4115\n",
            "Epoch: 28 \tTraining Loss: 731.7533 \tTraining Accuracy: 9.9746 \tValidation Loss: 1787.2914 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 22315.1532\n",
            "Validation loss decreased (1829.795833 --> 1787.291420).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 723.2403 \tTraining Accuracy: 10.2234 \tValidation Loss: 1746.1559 \tValidation Accuracy: 9.4922 \ttrain_kl_div: 21480.9866\n",
            "Validation loss decreased (1787.291420 --> 1746.155865).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 718.8035 \tTraining Accuracy: 9.8826 \tValidation Loss: 1666.2703 \tValidation Accuracy: 9.8535 \ttrain_kl_div: 19916.2550\n",
            "Validation loss decreased (1746.155865 --> 1666.270349).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 708.5948 \tTraining Accuracy: 9.9423 \tValidation Loss: 1654.2303 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 19659.1492\n",
            "Validation loss decreased (1666.270349 --> 1654.230272).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 707.4325 \tTraining Accuracy: 9.9398 \tValidation Loss: 1590.2211 \tValidation Accuracy: 9.8242 \ttrain_kl_div: 18385.6502\n",
            "Validation loss decreased (1654.230272 --> 1590.221146).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 698.7979 \tTraining Accuracy: 10.0269 \tValidation Loss: 1642.6957 \tValidation Accuracy: 9.3945 \ttrain_kl_div: 19287.3609\n",
            "Epoch: 34 \tTraining Loss: 705.6655 \tTraining Accuracy: 9.8278 \tValidation Loss: 1554.1743 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 17598.8126\n",
            "Validation loss decreased (1590.221146 --> 1554.174329).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 694.0844 \tTraining Accuracy: 9.8229 \tValidation Loss: 1600.8100 \tValidation Accuracy: 10.1953 \ttrain_kl_div: 18446.5976\n",
            "Epoch: 36 \tTraining Loss: 700.4564 \tTraining Accuracy: 9.5641 \tValidation Loss: 1530.8874 \tValidation Accuracy: 9.9023 \ttrain_kl_div: 17134.8779\n",
            "Validation loss decreased (1554.174329 --> 1530.887392).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 691.4425 \tTraining Accuracy: 9.9249 \tValidation Loss: 1626.9568 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 18723.7343\n",
            "Epoch: 38 \tTraining Loss: 701.9665 \tTraining Accuracy: 9.9224 \tValidation Loss: 1633.8219 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 18856.8321\n",
            "Epoch: 39 \tTraining Loss: 701.0686 \tTraining Accuracy: 9.7930 \tValidation Loss: 1724.0621 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 20451.1208\n",
            "Epoch: 40 \tTraining Loss: 711.2797 \tTraining Accuracy: 10.0468 \tValidation Loss: 1731.9216 \tValidation Accuracy: 10.0391 \ttrain_kl_div: 20493.2618\n",
            "Epoch: 41 \tTraining Loss: 711.3093 \tTraining Accuracy: 10.0194 \tValidation Loss: 1839.5358 \tValidation Accuracy: 10.3027 \ttrain_kl_div: 22352.4471\n",
            "Epoch: 42 \tTraining Loss: 722.8809 \tTraining Accuracy: 10.2632 \tValidation Loss: 1869.4998 \tValidation Accuracy: 9.3945 \ttrain_kl_div: 22870.0002\n",
            "Epoch 00044: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch: 43 \tTraining Loss: 724.2779 \tTraining Accuracy: 9.9149 \tValidation Loss: 2229.0149 \tValidation Accuracy: 9.8633 \ttrain_kl_div: 29304.9163\n",
            "Epoch: 44 \tTraining Loss: 794.4067 \tTraining Accuracy: 10.0393 \tValidation Loss: 1670.6063 \tValidation Accuracy: 9.8047 \ttrain_kl_div: 22321.7189\n",
            "Epoch: 45 \tTraining Loss: 725.2719 \tTraining Accuracy: 10.0095 \tValidation Loss: 1356.1437 \tValidation Accuracy: 9.6191 \ttrain_kl_div: 15725.1030\n",
            "Validation loss decreased (1530.887392 --> 1356.143738).  Saving model ...\n",
            "Epoch: 46 \tTraining Loss: 686.0319 \tTraining Accuracy: 9.7134 \tValidation Loss: 1158.6272 \tValidation Accuracy: 10.5859 \ttrain_kl_div: 11635.7992\n",
            "Validation loss decreased (1356.143738 --> 1158.627156).  Saving model ...\n",
            "Epoch: 47 \tTraining Loss: 661.5462 \tTraining Accuracy: 9.8378 \tValidation Loss: 1031.1149 \tValidation Accuracy: 9.3457 \ttrain_kl_div: 8994.4577\n",
            "Validation loss decreased (1158.627156 --> 1031.114882).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 645.6824 \tTraining Accuracy: 10.1861 \tValidation Loss: 946.9257 \tValidation Accuracy: 10.1270 \ttrain_kl_div: 7249.7083\n",
            "Validation loss decreased (1031.114882 --> 946.925742).  Saving model ...\n",
            "Epoch: 49 \tTraining Loss: 635.0915 \tTraining Accuracy: 10.1911 \tValidation Loss: 890.7092 \tValidation Accuracy: 10.1660 \ttrain_kl_div: 6089.3238\n",
            "Validation loss decreased (946.925742 --> 890.709163).  Saving model ...\n",
            "Epoch: 50 \tTraining Loss: 628.2363 \tTraining Accuracy: 9.9821 \tValidation Loss: 852.8487 \tValidation Accuracy: 10.2441 \ttrain_kl_div: 5305.4276\n",
            "Validation loss decreased (890.709163 --> 852.848679).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 623.5355 \tTraining Accuracy: 10.0518 \tValidation Loss: 827.2785 \tValidation Accuracy: 9.4434 \ttrain_kl_div: 4764.4535\n",
            "Validation loss decreased (852.848679 --> 827.278484).  Saving model ...\n",
            "Epoch: 52 \tTraining Loss: 620.2213 \tTraining Accuracy: 9.7557 \tValidation Loss: 808.3665 \tValidation Accuracy: 9.5312 \ttrain_kl_div: 4379.2982\n",
            "Validation loss decreased (827.278484 --> 808.366481).  Saving model ...\n",
            "Epoch: 53 \tTraining Loss: 617.9962 \tTraining Accuracy: 10.4474 \tValidation Loss: 794.7006 \tValidation Accuracy: 10.4004 \ttrain_kl_div: 4100.9934\n",
            "Validation loss decreased (808.366481 --> 794.700571).  Saving model ...\n",
            "Epoch: 54 \tTraining Loss: 616.3360 \tTraining Accuracy: 10.1065 \tValidation Loss: 784.6931 \tValidation Accuracy: 10.2148 \ttrain_kl_div: 3887.2127\n",
            "Validation loss decreased (794.700571 --> 784.693111).  Saving model ...\n",
            "Epoch: 55 \tTraining Loss: 614.7568 \tTraining Accuracy: 10.0318 \tValidation Loss: 775.4028 \tValidation Accuracy: 10.0000 \ttrain_kl_div: 3708.8820\n",
            "Validation loss decreased (784.693111 --> 775.402820).  Saving model ...\n",
            "Epoch: 56 \tTraining Loss: 613.3732 \tTraining Accuracy: 9.9821 \tValidation Loss: 768.0904 \tValidation Accuracy: 9.5117 \ttrain_kl_div: 3554.3703\n",
            "Validation loss decreased (775.402820 --> 768.090401).  Saving model ...\n",
            "Epoch: 57 \tTraining Loss: 613.2694 \tTraining Accuracy: 10.2657 \tValidation Loss: 763.0344 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 3433.3011\n",
            "Validation loss decreased (768.090401 --> 763.034435).  Saving model ...\n",
            "Epoch: 58 \tTraining Loss: 612.6020 \tTraining Accuracy: 9.7184 \tValidation Loss: 757.6194 \tValidation Accuracy: 10.7617 \ttrain_kl_div: 3322.7403\n",
            "Validation loss decreased (763.034435 --> 757.619437).  Saving model ...\n",
            "Epoch: 59 \tTraining Loss: 611.1179 \tTraining Accuracy: 9.7880 \tValidation Loss: 752.2657 \tValidation Accuracy: 9.6875 \ttrain_kl_div: 3213.3952\n",
            "Validation loss decreased (757.619437 --> 752.265739).  Saving model ...\n",
            "Epoch: 60 \tTraining Loss: 611.1778 \tTraining Accuracy: 9.7233 \tValidation Loss: 748.6078 \tValidation Accuracy: 9.9316 \ttrain_kl_div: 3119.1330\n",
            "Validation loss decreased (752.265739 --> 748.607770).  Saving model ...\n",
            "Epoch: 61 \tTraining Loss: 610.3961 \tTraining Accuracy: 9.9920 \tValidation Loss: 744.7568 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 3045.2459\n",
            "Validation loss decreased (748.607770 --> 744.756837).  Saving model ...\n",
            "Epoch: 62 \tTraining Loss: 609.9764 \tTraining Accuracy: 9.9473 \tValidation Loss: 739.7349 \tValidation Accuracy: 9.8145 \ttrain_kl_div: 2967.7392\n",
            "Validation loss decreased (744.756837 --> 739.734921).  Saving model ...\n",
            "Epoch: 63 \tTraining Loss: 609.4480 \tTraining Accuracy: 9.9423 \tValidation Loss: 736.8910 \tValidation Accuracy: 9.9805 \ttrain_kl_div: 2902.7980\n",
            "Validation loss decreased (739.734921 --> 736.890971).  Saving model ...\n",
            "Epoch: 64 \tTraining Loss: 609.0688 \tTraining Accuracy: 10.0518 \tValidation Loss: 734.5455 \tValidation Accuracy: 9.4141 \ttrain_kl_div: 2844.8721\n",
            "Validation loss decreased (736.890971 --> 734.545499).  Saving model ...\n",
            "Epoch: 65 \tTraining Loss: 609.1819 \tTraining Accuracy: 10.0741 \tValidation Loss: 733.1471 \tValidation Accuracy: 10.3027 \ttrain_kl_div: 2792.2482\n",
            "Validation loss decreased (734.545499 --> 733.147148).  Saving model ...\n",
            "Epoch: 66 \tTraining Loss: 608.8902 \tTraining Accuracy: 10.2881 \tValidation Loss: 731.8217 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 2778.2813\n",
            "Validation loss decreased (733.147148 --> 731.821713).  Saving model ...\n",
            "Epoch: 67 \tTraining Loss: 608.4904 \tTraining Accuracy: 10.0741 \tValidation Loss: 728.5314 \tValidation Accuracy: 10.4688 \ttrain_kl_div: 2717.8439\n",
            "Validation loss decreased (731.821713 --> 728.531424).  Saving model ...\n",
            "Epoch: 68 \tTraining Loss: 608.0303 \tTraining Accuracy: 9.8378 \tValidation Loss: 726.4105 \tValidation Accuracy: 9.5898 \ttrain_kl_div: 2665.9492\n",
            "Validation loss decreased (728.531424 --> 726.410547).  Saving model ...\n",
            "Epoch: 69 \tTraining Loss: 608.2716 \tTraining Accuracy: 9.9273 \tValidation Loss: 730.7927 \tValidation Accuracy: 10.3809 \ttrain_kl_div: 2687.0614\n",
            "Epoch: 70 \tTraining Loss: 608.5622 \tTraining Accuracy: 9.9622 \tValidation Loss: 730.5264 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 2718.7100\n",
            "Epoch: 71 \tTraining Loss: 608.3254 \tTraining Accuracy: 9.8577 \tValidation Loss: 738.0221 \tValidation Accuracy: 9.7266 \ttrain_kl_div: 2800.7605\n",
            "Epoch: 72 \tTraining Loss: 609.4738 \tTraining Accuracy: 9.8751 \tValidation Loss: 750.3444 \tValidation Accuracy: 9.6191 \ttrain_kl_div: 3040.3444\n",
            "Epoch: 73 \tTraining Loss: 610.4511 \tTraining Accuracy: 10.0169 \tValidation Loss: 775.4260 \tValidation Accuracy: 10.4785 \ttrain_kl_div: 3453.4043\n",
            "Epoch: 74 \tTraining Loss: 612.9357 \tTraining Accuracy: 9.7333 \tValidation Loss: 805.3310 \tValidation Accuracy: 9.9414 \ttrain_kl_div: 3988.2718\n",
            "Epoch 00076: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 75 \tTraining Loss: 616.0550 \tTraining Accuracy: 9.9721 \tValidation Loss: 842.1694 \tValidation Accuracy: 10.4102 \ttrain_kl_div: 4630.1797\n",
            "Epoch: 76 \tTraining Loss: 622.0509 \tTraining Accuracy: 10.2060 \tValidation Loss: 791.6417 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 4091.9386\n",
            "Epoch: 77 \tTraining Loss: 615.5871 \tTraining Accuracy: 10.0791 \tValidation Loss: 763.1091 \tValidation Accuracy: 10.1953 \ttrain_kl_div: 3491.3771\n",
            "Epoch: 78 \tTraining Loss: 612.0464 \tTraining Accuracy: 10.1115 \tValidation Loss: 746.1116 \tValidation Accuracy: 9.5996 \ttrain_kl_div: 3122.2422\n",
            "Epoch: 79 \tTraining Loss: 610.2119 \tTraining Accuracy: 10.0219 \tValidation Loss: 734.0328 \tValidation Accuracy: 9.8828 \ttrain_kl_div: 2884.9121\n",
            "Epoch: 80 \tTraining Loss: 608.9845 \tTraining Accuracy: 10.1687 \tValidation Loss: 727.2592 \tValidation Accuracy: 10.0000 \ttrain_kl_div: 2732.6856\n",
            "Epoch: 81 \tTraining Loss: 607.9935 \tTraining Accuracy: 9.8129 \tValidation Loss: 722.1207 \tValidation Accuracy: 9.1992 \ttrain_kl_div: 2628.3958\n",
            "Validation loss decreased (726.410547 --> 722.120686).  Saving model ...\n",
            "Epoch: 82 \tTraining Loss: 607.4312 \tTraining Accuracy: 10.1090 \tValidation Loss: 719.3680 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 2558.5687\n",
            "Validation loss decreased (722.120686 --> 719.368002).  Saving model ...\n",
            "Epoch: 83 \tTraining Loss: 606.7908 \tTraining Accuracy: 10.3006 \tValidation Loss: 716.7210 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 2501.4498\n",
            "Validation loss decreased (719.368002 --> 716.720981).  Saving model ...\n",
            "Epoch: 84 \tTraining Loss: 606.4762 \tTraining Accuracy: 10.2309 \tValidation Loss: 714.3870 \tValidation Accuracy: 9.7949 \ttrain_kl_div: 2470.4539\n",
            "Validation loss decreased (716.720981 --> 714.387032).  Saving model ...\n",
            "Epoch: 85 \tTraining Loss: 606.3247 \tTraining Accuracy: 10.1090 \tValidation Loss: 712.8358 \tValidation Accuracy: 9.7266 \ttrain_kl_div: 2438.7004\n",
            "Validation loss decreased (714.387032 --> 712.835785).  Saving model ...\n",
            "Epoch: 86 \tTraining Loss: 605.9421 \tTraining Accuracy: 9.7880 \tValidation Loss: 711.2767 \tValidation Accuracy: 10.1172 \ttrain_kl_div: 2414.3925\n",
            "Validation loss decreased (712.835785 --> 711.276715).  Saving model ...\n",
            "Epoch: 87 \tTraining Loss: 606.0753 \tTraining Accuracy: 9.8577 \tValidation Loss: 710.8595 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 2395.8011\n",
            "Validation loss decreased (711.276715 --> 710.859479).  Saving model ...\n",
            "Epoch: 88 \tTraining Loss: 605.8770 \tTraining Accuracy: 10.0368 \tValidation Loss: 710.1713 \tValidation Accuracy: 9.2578 \ttrain_kl_div: 2381.4181\n",
            "Validation loss decreased (710.859479 --> 710.171266).  Saving model ...\n",
            "Epoch: 89 \tTraining Loss: 605.7447 \tTraining Accuracy: 9.9970 \tValidation Loss: 709.4726 \tValidation Accuracy: 10.4102 \ttrain_kl_div: 2359.6432\n",
            "Validation loss decreased (710.171266 --> 709.472580).  Saving model ...\n",
            "Epoch: 90 \tTraining Loss: 605.6495 \tTraining Accuracy: 10.0940 \tValidation Loss: 708.8359 \tValidation Accuracy: 9.5508 \ttrain_kl_div: 2348.6293\n",
            "Validation loss decreased (709.472580 --> 708.835881).  Saving model ...\n",
            "Epoch: 91 \tTraining Loss: 605.6948 \tTraining Accuracy: 10.0269 \tValidation Loss: 708.9853 \tValidation Accuracy: 9.6777 \ttrain_kl_div: 2336.7857\n",
            "Epoch: 92 \tTraining Loss: 605.6317 \tTraining Accuracy: 10.1164 \tValidation Loss: 708.6783 \tValidation Accuracy: 9.8730 \ttrain_kl_div: 2334.4216\n",
            "Validation loss decreased (708.835881 --> 708.678304).  Saving model ...\n",
            "Epoch: 93 \tTraining Loss: 605.5898 \tTraining Accuracy: 10.0493 \tValidation Loss: 707.8050 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 2316.9714\n",
            "Validation loss decreased (708.678304 --> 707.805002).  Saving model ...\n",
            "Epoch: 94 \tTraining Loss: 605.4091 \tTraining Accuracy: 10.0418 \tValidation Loss: 706.6901 \tValidation Accuracy: 10.4199 \ttrain_kl_div: 2301.2263\n",
            "Validation loss decreased (707.805002 --> 706.690149).  Saving model ...\n",
            "Epoch: 95 \tTraining Loss: 605.9074 \tTraining Accuracy: 9.9572 \tValidation Loss: 707.8728 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 2304.7545\n",
            "Epoch: 96 \tTraining Loss: 605.6553 \tTraining Accuracy: 10.0468 \tValidation Loss: 707.7646 \tValidation Accuracy: 9.6484 \ttrain_kl_div: 2310.9160\n",
            "Epoch: 97 \tTraining Loss: 605.3597 \tTraining Accuracy: 9.8676 \tValidation Loss: 706.1575 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 2274.2904\n",
            "Validation loss decreased (706.690149 --> 706.157503).  Saving model ...\n",
            "Epoch: 98 \tTraining Loss: 605.3099 \tTraining Accuracy: 10.0368 \tValidation Loss: 705.9803 \tValidation Accuracy: 9.8438 \ttrain_kl_div: 2267.5231\n",
            "Validation loss decreased (706.157503 --> 705.980286).  Saving model ...\n",
            "Epoch: 99 \tTraining Loss: 605.6833 \tTraining Accuracy: 10.2583 \tValidation Loss: 707.2603 \tValidation Accuracy: 9.7754 \ttrain_kl_div: 2283.3022\n"
          ]
        }
      ],
      "source": [
        "!python main_bayesian.py --net_type alexnet --dataset CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCYsBTDxjG6M",
        "outputId": "a7664937-38b9-43a8-b62a-6f65b2ac41b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters initialized\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch: 0 \tTraining Loss: 776.3799 \tTraining Accuracy: 9.9191 \tValidation Loss: 5577.7337 \tValidation Accuracy: 10.4925 \ttrain_kl_div: 186393.1649\n",
            "Validation loss decreased (inf --> 5577.733730).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 770.0099 \tTraining Accuracy: 9.8068 \tValidation Loss: 35057.3936 \tValidation Accuracy: 9.7903 \ttrain_kl_div: 1295347.6917\n",
            "Epoch: 2 \tTraining Loss: 3773.7852 \tTraining Accuracy: 10.0914 \tValidation Loss: 50690.0110 \tValidation Accuracy: 9.1673 \ttrain_kl_div: 1864897.8236\n",
            "Epoch: 3 \tTraining Loss: 5701.4295 \tTraining Accuracy: 9.9666 \tValidation Loss: 24521.0780 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 935390.9853\n",
            "Epoch: 4 \tTraining Loss: 3035.5751 \tTraining Accuracy: 9.8043 \tValidation Loss: 14580.3585 \tValidation Accuracy: 9.4244 \ttrain_kl_div: 557189.7100\n",
            "Epoch: 5 \tTraining Loss: 1921.9565 \tTraining Accuracy: 10.0015 \tValidation Loss: 10684.7462 \tValidation Accuracy: 9.9486 \ttrain_kl_div: 402895.1502\n",
            "Epoch: 6 \tTraining Loss: 1425.0317 \tTraining Accuracy: 9.8393 \tValidation Loss: 16804.7242 \tValidation Accuracy: 10.4331 \ttrain_kl_div: 622706.5531\n",
            "Epoch 00008: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch: 7 \tTraining Loss: 1957.2535 \tTraining Accuracy: 9.9166 \tValidation Loss: 35559.4514 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 1316653.5190\n",
            "Epoch: 8 \tTraining Loss: 4620.7850 \tTraining Accuracy: 9.9091 \tValidation Loss: 22257.2749 \tValidation Accuracy: 9.6025 \ttrain_kl_div: 884160.1472\n",
            "Epoch: 9 \tTraining Loss: 3011.5103 \tTraining Accuracy: 10.0839 \tValidation Loss: 15972.8242 \tValidation Accuracy: 9.9782 \ttrain_kl_div: 627380.4669\n",
            "Epoch: 10 \tTraining Loss: 2241.2334 \tTraining Accuracy: 10.0614 \tValidation Loss: 12153.4400 \tValidation Accuracy: 9.8398 \ttrain_kl_div: 473377.8767\n",
            "Epoch: 11 \tTraining Loss: 1769.6123 \tTraining Accuracy: 9.9366 \tValidation Loss: 9558.8500 \tValidation Accuracy: 9.7310 \ttrain_kl_div: 369301.2442\n",
            "Epoch: 12 \tTraining Loss: 1448.5604 \tTraining Accuracy: 9.8817 \tValidation Loss: 7678.0070 \tValidation Accuracy: 10.0079 \ttrain_kl_div: 294068.6528\n",
            "Epoch: 13 \tTraining Loss: 1215.1636 \tTraining Accuracy: 10.0414 \tValidation Loss: 6259.5858 \tValidation Accuracy: 9.8101 \ttrain_kl_div: 237420.1371\n",
            "Epoch: 14 \tTraining Loss: 1039.0699 \tTraining Accuracy: 10.0864 \tValidation Loss: 5165.6651 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 193788.7771\n",
            "Validation loss decreased (5577.733730 --> 5165.665104).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 903.1162 \tTraining Accuracy: 10.3884 \tValidation Loss: 4318.4968 \tValidation Accuracy: 9.9782 \ttrain_kl_div: 160003.2222\n",
            "Validation loss decreased (5165.665104 --> 4318.496845).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 797.9158 \tTraining Accuracy: 9.7469 \tValidation Loss: 3664.7197 \tValidation Accuracy: 10.0672 \ttrain_kl_div: 133896.1402\n",
            "Validation loss decreased (4318.496845 --> 3664.719733).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 716.1104 \tTraining Accuracy: 10.1388 \tValidation Loss: 3154.7053 \tValidation Accuracy: 9.6519 \ttrain_kl_div: 113605.7428\n",
            "Validation loss decreased (3664.719733 --> 3154.705280).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 652.8023 \tTraining Accuracy: 10.3135 \tValidation Loss: 2754.4099 \tValidation Accuracy: 10.2354 \ttrain_kl_div: 97594.3213\n",
            "Validation loss decreased (3154.705280 --> 2754.409885).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 603.0702 \tTraining Accuracy: 10.0314 \tValidation Loss: 2429.1207 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 84621.8932\n",
            "Validation loss decreased (2754.409885 --> 2429.120653).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 562.2269 \tTraining Accuracy: 9.8567 \tValidation Loss: 2162.0031 \tValidation Accuracy: 9.8299 \ttrain_kl_div: 73951.3071\n",
            "Validation loss decreased (2429.120653 --> 2162.003076).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 528.3727 \tTraining Accuracy: 9.9341 \tValidation Loss: 1945.3463 \tValidation Accuracy: 9.6420 \ttrain_kl_div: 65164.3425\n",
            "Validation loss decreased (2162.003076 --> 1945.346284).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 500.1217 \tTraining Accuracy: 9.9715 \tValidation Loss: 1775.5376 \tValidation Accuracy: 9.8794 \ttrain_kl_div: 58351.0773\n",
            "Validation loss decreased (1945.346284 --> 1775.537646).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 477.7470 \tTraining Accuracy: 9.8992 \tValidation Loss: 1651.2699 \tValidation Accuracy: 10.0475 \ttrain_kl_div: 53259.1599\n",
            "Validation loss decreased (1775.537646 --> 1651.269902).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 461.4860 \tTraining Accuracy: 10.0589 \tValidation Loss: 1542.3515 \tValidation Accuracy: 9.9288 \ttrain_kl_div: 48575.8929\n",
            "Validation loss decreased (1651.269902 --> 1542.351520).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 445.8833 \tTraining Accuracy: 9.7794 \tValidation Loss: 1405.2676 \tValidation Accuracy: 9.9980 \ttrain_kl_div: 43313.3230\n",
            "Validation loss decreased (1542.351520 --> 1405.267560).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 428.5595 \tTraining Accuracy: 9.7444 \tValidation Loss: 1310.3686 \tValidation Accuracy: 9.8002 \ttrain_kl_div: 39186.2178\n",
            "Validation loss decreased (1405.267560 --> 1310.368646).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 416.1696 \tTraining Accuracy: 9.8842 \tValidation Loss: 1248.4711 \tValidation Accuracy: 10.5320 \ttrain_kl_div: 36674.7448\n",
            "Validation loss decreased (1310.368646 --> 1248.471107).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 407.2133 \tTraining Accuracy: 9.8692 \tValidation Loss: 1187.7760 \tValidation Accuracy: 9.6321 \ttrain_kl_div: 34240.1544\n",
            "Validation loss decreased (1248.471107 --> 1187.776014).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 399.0479 \tTraining Accuracy: 10.1338 \tValidation Loss: 1166.5920 \tValidation Accuracy: 9.8398 \ttrain_kl_div: 33223.0013\n",
            "Validation loss decreased (1187.776014 --> 1166.592006).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 394.3528 \tTraining Accuracy: 10.0364 \tValidation Loss: 1146.0099 \tValidation Accuracy: 9.9486 \ttrain_kl_div: 32416.6054\n",
            "Validation loss decreased (1166.592006 --> 1146.009888).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 391.2132 \tTraining Accuracy: 10.1013 \tValidation Loss: 1165.0828 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 32633.6680\n",
            "Epoch: 32 \tTraining Loss: 392.2628 \tTraining Accuracy: 9.8792 \tValidation Loss: 1079.7781 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 29508.1695\n",
            "Validation loss decreased (1146.009888 --> 1079.778129).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 381.9633 \tTraining Accuracy: 10.0190 \tValidation Loss: 982.4846 \tValidation Accuracy: 9.7013 \ttrain_kl_div: 25943.7327\n",
            "Validation loss decreased (1079.778129 --> 982.484640).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 371.1645 \tTraining Accuracy: 9.8143 \tValidation Loss: 936.1911 \tValidation Accuracy: 9.6717 \ttrain_kl_div: 24106.9518\n",
            "Validation loss decreased (982.484640 --> 936.191114).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 366.3343 \tTraining Accuracy: 9.8243 \tValidation Loss: 926.9874 \tValidation Accuracy: 9.6618 \ttrain_kl_div: 23692.5493\n",
            "Validation loss decreased (936.191114 --> 926.987353).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 364.8243 \tTraining Accuracy: 10.0339 \tValidation Loss: 943.9314 \tValidation Accuracy: 10.4035 \ttrain_kl_div: 24150.9209\n",
            "Epoch: 37 \tTraining Loss: 366.0988 \tTraining Accuracy: 9.7494 \tValidation Loss: 929.4333 \tValidation Accuracy: 9.8497 \ttrain_kl_div: 23565.7841\n",
            "Epoch: 38 \tTraining Loss: 363.9215 \tTraining Accuracy: 9.8967 \tValidation Loss: 897.6358 \tValidation Accuracy: 9.6025 \ttrain_kl_div: 22365.1628\n",
            "Validation loss decreased (926.987353 --> 897.635845).  Saving model ...\n",
            "Epoch: 39 \tTraining Loss: 360.4746 \tTraining Accuracy: 9.9790 \tValidation Loss: 897.1454 \tValidation Accuracy: 9.3849 \ttrain_kl_div: 22323.1660\n",
            "Validation loss decreased (897.635845 --> 897.145353).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 359.9855 \tTraining Accuracy: 9.9541 \tValidation Loss: 888.0628 \tValidation Accuracy: 9.7013 \ttrain_kl_div: 22126.3081\n",
            "Validation loss decreased (897.145353 --> 888.062832).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 359.3923 \tTraining Accuracy: 10.1213 \tValidation Loss: 887.7948 \tValidation Accuracy: 9.8299 \ttrain_kl_div: 22055.4117\n",
            "Validation loss decreased (888.062832 --> 887.794847).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 359.5022 \tTraining Accuracy: 9.8642 \tValidation Loss: 877.0194 \tValidation Accuracy: 9.8299 \ttrain_kl_div: 21655.2510\n",
            "Validation loss decreased (887.794847 --> 877.019401).  Saving model ...\n",
            "Epoch: 43 \tTraining Loss: 357.7675 \tTraining Accuracy: 10.0689 \tValidation Loss: 840.9196 \tValidation Accuracy: 9.8497 \ttrain_kl_div: 20303.2915\n",
            "Validation loss decreased (877.019401 --> 840.919599).  Saving model ...\n",
            "Traceback (most recent call last):\n",
            "  File \"main_bayesian.py\", line 152, in <module>\n",
            "    run(args.dataset, args.net_type)\n",
            "  File \"main_bayesian.py\", line 127, in run\n",
            "    train_loss, train_acc, train_kl = train_model(net, optimizer, criterion, train_loader,beta_type,num_ens=train_ens)\n",
            "  File \"main_bayesian.py\", line 58, in train_model\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python main_bayesian.py --net_type alexnet --dataset MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BaUwRWhw4gZ"
      },
      "source": [
        "### Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOhlufxlc_Td",
        "outputId": "fb080c3e-9e61-4bff-ee29-fb61a5a3910c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-08 19:35:45.818605: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-08 19:35:46.703165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parameters initialized\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 91379607.90it/s]\n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 61709472.15it/s]\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 27319126.05it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 27529665.85it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "0it [00:09, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/main_bayesian.py\", line 155, in <module>\n",
            "    run(args.dataset, args.net_type)\n",
            "  File \"/content/main_bayesian.py\", line 130, in run\n",
            "    train_loss, train_acc, train_kl = train_model(net, optimizer, criterion, train_loader,beta_type,num_ens=train_ens)\n",
            "  File \"/content/main_bayesian.py\", line 52, in train_model\n",
            "    net_out, kl = net(inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/layers/misc.py\", line 23, in forward\n",
            "    kl = kl + module.kl_loss()\n",
            "  File \"/content/layers/BBB/BBBConv.py\", line 80, in kl_loss\n",
            "    kl = KL_DIV(self.prior_mu, self.prior_sigma, self.W_mu, self.W_sigma)\n",
            "  File \"/content/metrics.py\", line 29, in calculate_kl\n",
            "    kl = 0.5 * (2 * torch.log(sig_p / sig_q) - 1 + (sig_q / sig_p).pow(2) + ((mu_p - mu_q) / sig_p).pow(2)).sum()\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.40 GiB already allocated; 6.81 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ],
      "source": [
        "!python main_bayesian.py --net_type resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbYPDYvnT_I5"
      },
      "source": [
        "### Custom CNN - 4conv3fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJUDHhh2dB1h"
      },
      "outputs": [],
      "source": [
        "!python main_bayesian.py --net_type 4conv3fc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z_hTbyoUDrZ"
      },
      "source": [
        "### VGG11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6VhQQe5dFhY",
        "outputId": "2f743c15-9bda-4524-f9a8-cbfd19403fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-08 21:10:07.829554: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-08 21:10:08.942411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parameters initialized\n",
            "188it [08:36,  2.75s/it]\n",
            "Epoch: 0 \tTraining Loss: 2561237.6819 \tTraining Accuracy: 10.7276 \tValidation Loss: 17791317.6237 \tValidation Accuracy: 10.6632 \ttrain_kl_div: 419778969.5319\n",
            "Validation loss decreased (inf --> 17791317.623722).  Saving model ...\n",
            "91it [04:11,  2.86s/it]"
          ]
        }
      ],
      "source": [
        "!python main_bayesian.py --net_type vgg11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzpHpKVYxihI"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbWxxuLKGyjJ",
        "outputId": "46215b38-eff0-4aef-e236-d3219956967f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/MNIST/ (stored 0%)\n",
            "  adding: content/checkpoints/MNIST/bayesian/ (stored 0%)\n",
            "  adding: content/checkpoints/MNIST/bayesian/model_lenet_lrt_softplus.pt (deflated 21%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/checkpoints.zip /content/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L9LsS8IpGyjJ",
        "outputId": "ed0df6cf-3060-4fdd-c788-739a0326dd57"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e4c8b5c6-f17f-4012-878f-09f81561b0bc\", \"checkpoints.zip\", 394134)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/checkpoints.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyr9tWRkbdbL",
        "outputId": "8d932836-100d-47ba-92d1-2689320943cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/Bayes-lenet-MNIST/ (stored 0%)\n",
            "  adding: content/Bayes-lenet-MNIST/events.out.tfevents.1682996974.d2a2e2fa3a21.737.0 (deflated 68%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/bl_mnist.zip /content/Bayes-lenet-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ogq5U3zObdbS",
        "outputId": "e4717318-4c3b-4520-c32f-59bb79134185"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ed1fa111-0c89-4371-92b2-297ac3134738\", \"bl_mnist.zip\", 6770)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/bl_mnist.zip\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WHcX_QleGrm5"
      },
      "source": [
        "# Normal Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0gOWV2kxpML"
      },
      "source": [
        "### LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_838mGmYH9AV",
        "outputId": "d0b4c10f-fd2e-40e9-a988-53ed5de6eec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-02 03:09:16.939235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-02 03:09:17.841597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parameters initialized\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 254092989.07it/s]\n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 151989578.20it/s]\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 64848438.27it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 33837528.90it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 188/188 [00:15<00:00, 12.24it/s]\n",
            "100% 47/47 [00:02<00:00, 18.65it/s]\n",
            "Epoch: 1 \tTraining Loss: 0.6292 \tTraining Accuracy: 65.1967 \tValidation Loss: 0.2131 \tValidation Accuracy: 18.7450\n",
            "Validation loss decreased (inf --> 0.213055).  Saving model ...\n",
            "100% 188/188 [00:08<00:00, 22.35it/s]\n",
            "100% 47/47 [00:01<00:00, 23.57it/s]\n",
            "Epoch: 2 \tTraining Loss: 0.1568 \tTraining Accuracy: 76.1817 \tValidation Loss: 0.1228 \tValidation Accuracy: 19.2867\n",
            "Validation loss decreased (0.213055 --> 0.122755).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 20.58it/s]\n",
            "100% 47/47 [00:02<00:00, 23.09it/s]\n",
            "Epoch: 3 \tTraining Loss: 0.1068 \tTraining Accuracy: 77.2883 \tValidation Loss: 0.0947 \tValidation Accuracy: 19.4467\n",
            "Validation loss decreased (0.122755 --> 0.094657).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 20.03it/s]\n",
            "100% 47/47 [00:02<00:00, 22.83it/s]\n",
            "Epoch: 4 \tTraining Loss: 0.0832 \tTraining Accuracy: 77.9433 \tValidation Loss: 0.0708 \tValidation Accuracy: 19.5733\n",
            "Validation loss decreased (0.094657 --> 0.070832).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 19.93it/s]\n",
            "100% 47/47 [00:03<00:00, 14.50it/s]\n",
            "Epoch: 5 \tTraining Loss: 0.0693 \tTraining Accuracy: 78.2533 \tValidation Loss: 0.0646 \tValidation Accuracy: 19.6150\n",
            "Validation loss decreased (0.070832 --> 0.064550).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 20.36it/s]\n",
            "100% 47/47 [00:02<00:00, 22.98it/s]\n",
            "Epoch: 6 \tTraining Loss: 0.0609 \tTraining Accuracy: 78.4583 \tValidation Loss: 0.0540 \tValidation Accuracy: 19.6900\n",
            "Validation loss decreased (0.064550 --> 0.053988).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 20.09it/s]\n",
            "100% 47/47 [00:02<00:00, 23.01it/s]\n",
            "Epoch: 7 \tTraining Loss: 0.0524 \tTraining Accuracy: 78.7183 \tValidation Loss: 0.0579 \tValidation Accuracy: 19.6367\n",
            "100% 188/188 [00:09<00:00, 19.96it/s]\n",
            "100% 47/47 [00:02<00:00, 22.01it/s]\n",
            "Epoch: 8 \tTraining Loss: 0.0448 \tTraining Accuracy: 78.8850 \tValidation Loss: 0.0450 \tValidation Accuracy: 19.7217\n",
            "Validation loss decreased (0.053988 --> 0.044994).  Saving model ...\n",
            "100% 188/188 [00:08<00:00, 21.14it/s]\n",
            "100% 47/47 [00:02<00:00, 18.90it/s]\n",
            "Epoch: 9 \tTraining Loss: 0.0404 \tTraining Accuracy: 79.0250 \tValidation Loss: 0.0465 \tValidation Accuracy: 19.7267\n",
            "100% 188/188 [00:08<00:00, 23.28it/s]\n",
            "100% 47/47 [00:03<00:00, 14.72it/s]\n",
            "Epoch: 10 \tTraining Loss: 0.0357 \tTraining Accuracy: 79.1667 \tValidation Loss: 0.0446 \tValidation Accuracy: 19.7350\n",
            "Validation loss decreased (0.044994 --> 0.044567).  Saving model ...\n",
            "100% 188/188 [00:08<00:00, 23.49it/s]\n",
            "100% 47/47 [00:02<00:00, 16.89it/s]\n",
            "Epoch: 11 \tTraining Loss: 0.0309 \tTraining Accuracy: 79.2450 \tValidation Loss: 0.0405 \tValidation Accuracy: 19.7667\n",
            "Validation loss decreased (0.044567 --> 0.040510).  Saving model ...\n",
            "100% 188/188 [00:08<00:00, 22.50it/s]\n",
            "100% 47/47 [00:02<00:00, 22.10it/s]\n",
            "Epoch: 12 \tTraining Loss: 0.0273 \tTraining Accuracy: 79.3067 \tValidation Loss: 0.0422 \tValidation Accuracy: 19.7383\n",
            "100% 188/188 [00:09<00:00, 20.54it/s]\n",
            "100% 47/47 [00:02<00:00, 22.84it/s]\n",
            "Epoch: 13 \tTraining Loss: 0.0251 \tTraining Accuracy: 79.3517 \tValidation Loss: 0.0448 \tValidation Accuracy: 19.7317\n",
            "100% 188/188 [00:09<00:00, 20.46it/s]\n",
            "100% 47/47 [00:02<00:00, 22.43it/s]\n",
            "Epoch: 14 \tTraining Loss: 0.0258 \tTraining Accuracy: 79.3150 \tValidation Loss: 0.0392 \tValidation Accuracy: 19.7583\n",
            "Validation loss decreased (0.040510 --> 0.039183).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 20.11it/s]\n",
            "100% 47/47 [00:02<00:00, 22.15it/s]\n",
            "Epoch: 15 \tTraining Loss: 0.0201 \tTraining Accuracy: 79.4900 \tValidation Loss: 0.0343 \tValidation Accuracy: 19.7983\n",
            "Validation loss decreased (0.039183 --> 0.034252).  Saving model ...\n",
            "100% 188/188 [00:09<00:00, 20.34it/s]\n",
            "100% 47/47 [00:02<00:00, 22.52it/s]\n",
            "Epoch: 16 \tTraining Loss: 0.0179 \tTraining Accuracy: 79.5533 \tValidation Loss: 0.0432 \tValidation Accuracy: 19.7433\n",
            "100% 188/188 [00:09<00:00, 19.93it/s]\n",
            "100% 47/47 [00:02<00:00, 21.50it/s]\n",
            "Epoch: 17 \tTraining Loss: 0.0181 \tTraining Accuracy: 79.5317 \tValidation Loss: 0.0385 \tValidation Accuracy: 19.7783\n",
            "100% 188/188 [00:08<00:00, 21.05it/s]\n",
            "100% 47/47 [00:02<00:00, 19.39it/s]\n",
            "Epoch: 18 \tTraining Loss: 0.0172 \tTraining Accuracy: 79.5467 \tValidation Loss: 0.0399 \tValidation Accuracy: 19.7750\n",
            "100% 188/188 [00:09<00:00, 19.93it/s]\n",
            "100% 47/47 [00:02<00:00, 18.55it/s]\n",
            "Epoch: 19 \tTraining Loss: 0.0140 \tTraining Accuracy: 79.6383 \tValidation Loss: 0.0380 \tValidation Accuracy: 19.8050\n",
            "100% 188/188 [00:08<00:00, 22.70it/s]\n",
            "100% 47/47 [00:03<00:00, 14.73it/s]\n",
            "Epoch: 20 \tTraining Loss: 0.0119 \tTraining Accuracy: 79.7283 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8033\n",
            "100% 188/188 [00:08<00:00, 23.38it/s]\n",
            "100% 47/47 [00:02<00:00, 16.88it/s]\n",
            "Epoch: 21 \tTraining Loss: 0.0115 \tTraining Accuracy: 79.7200 \tValidation Loss: 0.0462 \tValidation Accuracy: 19.7600\n",
            "100% 188/188 [00:08<00:00, 22.26it/s]\n",
            "100% 47/47 [00:02<00:00, 21.98it/s]\n",
            "Epoch 00022: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 22 \tTraining Loss: 0.0126 \tTraining Accuracy: 79.6867 \tValidation Loss: 0.0420 \tValidation Accuracy: 19.7850\n",
            "100% 188/188 [00:09<00:00, 20.00it/s]\n",
            "100% 47/47 [00:02<00:00, 22.40it/s]\n",
            "Epoch: 23 \tTraining Loss: 0.0053 \tTraining Accuracy: 79.8967 \tValidation Loss: 0.0354 \tValidation Accuracy: 19.8117\n",
            "100% 188/188 [00:10<00:00, 18.67it/s]\n",
            "100% 47/47 [00:02<00:00, 22.36it/s]\n",
            "Epoch: 24 \tTraining Loss: 0.0041 \tTraining Accuracy: 79.9300 \tValidation Loss: 0.0354 \tValidation Accuracy: 19.8283\n",
            "100% 188/188 [00:09<00:00, 20.22it/s]\n",
            "100% 47/47 [00:02<00:00, 16.63it/s]\n",
            "Epoch: 25 \tTraining Loss: 0.0037 \tTraining Accuracy: 79.9400 \tValidation Loss: 0.0352 \tValidation Accuracy: 19.8283\n",
            "100% 188/188 [00:09<00:00, 20.03it/s]\n",
            "100% 47/47 [00:02<00:00, 22.19it/s]\n",
            "Epoch: 26 \tTraining Loss: 0.0034 \tTraining Accuracy: 79.9317 \tValidation Loss: 0.0355 \tValidation Accuracy: 19.8317\n",
            "100% 188/188 [00:09<00:00, 20.25it/s]\n",
            "100% 47/47 [00:02<00:00, 21.92it/s]\n",
            "Epoch: 27 \tTraining Loss: 0.0032 \tTraining Accuracy: 79.9483 \tValidation Loss: 0.0356 \tValidation Accuracy: 19.8400\n",
            "100% 188/188 [00:09<00:00, 20.69it/s]\n",
            "100% 47/47 [00:02<00:00, 23.17it/s]\n",
            "Epoch: 28 \tTraining Loss: 0.0030 \tTraining Accuracy: 79.9533 \tValidation Loss: 0.0363 \tValidation Accuracy: 19.8317\n",
            "100% 188/188 [00:09<00:00, 20.59it/s]\n",
            "100% 47/47 [00:02<00:00, 22.89it/s]\n",
            "Epoch 00029: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 29 \tTraining Loss: 0.0029 \tTraining Accuracy: 79.9533 \tValidation Loss: 0.0364 \tValidation Accuracy: 19.8367\n",
            "100% 188/188 [00:09<00:00, 20.60it/s]\n",
            "100% 47/47 [00:02<00:00, 20.28it/s]\n",
            "Epoch: 30 \tTraining Loss: 0.0026 \tTraining Accuracy: 79.9600 \tValidation Loss: 0.0364 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.54it/s]\n",
            "100% 47/47 [00:02<00:00, 15.78it/s]\n",
            "Epoch: 31 \tTraining Loss: 0.0025 \tTraining Accuracy: 79.9600 \tValidation Loss: 0.0364 \tValidation Accuracy: 19.8417\n",
            "100% 188/188 [00:07<00:00, 23.62it/s]\n",
            "100% 47/47 [00:02<00:00, 17.09it/s]\n",
            "Epoch: 32 \tTraining Loss: 0.0025 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0365 \tValidation Accuracy: 19.8367\n",
            "100% 188/188 [00:08<00:00, 22.85it/s]\n",
            "100% 47/47 [00:02<00:00, 21.82it/s]\n",
            "Epoch: 33 \tTraining Loss: 0.0025 \tTraining Accuracy: 79.9617 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8400\n",
            "100% 188/188 [00:08<00:00, 20.99it/s]\n",
            "100% 47/47 [00:02<00:00, 22.43it/s]\n",
            "Epoch: 34 \tTraining Loss: 0.0025 \tTraining Accuracy: 79.9617 \tValidation Loss: 0.0365 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.39it/s]\n",
            "100% 47/47 [00:02<00:00, 21.60it/s]\n",
            "Epoch: 35 \tTraining Loss: 0.0025 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0365 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.47it/s]\n",
            "100% 47/47 [00:02<00:00, 23.00it/s]\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 36 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8400\n",
            "100% 188/188 [00:09<00:00, 20.43it/s]\n",
            "100% 47/47 [00:02<00:00, 22.29it/s]\n",
            "Epoch: 37 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.35it/s]\n",
            "100% 47/47 [00:02<00:00, 22.53it/s]\n",
            "Epoch: 38 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.70it/s]\n",
            "100% 47/47 [00:02<00:00, 22.81it/s]\n",
            "Epoch: 39 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9650 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.21it/s]\n",
            "100% 47/47 [00:02<00:00, 18.01it/s]\n",
            "Epoch: 40 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9650 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.63it/s]\n",
            "100% 47/47 [00:03<00:00, 14.40it/s]\n",
            "Epoch: 41 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.76it/s]\n",
            "100% 47/47 [00:02<00:00, 19.43it/s]\n",
            "Epoch: 42 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.41it/s]\n",
            "100% 47/47 [00:02<00:00, 22.96it/s]\n",
            "Epoch 00043: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 43 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 17.91it/s]\n",
            "100% 47/47 [00:02<00:00, 22.95it/s]\n",
            "Epoch: 44 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.49it/s]\n",
            "100% 47/47 [00:02<00:00, 17.26it/s]\n",
            "Epoch: 45 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.40it/s]\n",
            "100% 47/47 [00:02<00:00, 22.88it/s]\n",
            "Epoch: 46 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.86it/s]\n",
            "100% 47/47 [00:02<00:00, 22.65it/s]\n",
            "Epoch: 47 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.26it/s]\n",
            "100% 47/47 [00:02<00:00, 22.77it/s]\n",
            "Epoch: 48 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.53it/s]\n",
            "100% 47/47 [00:02<00:00, 23.38it/s]\n",
            "Epoch: 49 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.50it/s]\n",
            "100% 47/47 [00:02<00:00, 23.05it/s]\n",
            "Epoch 00050: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch: 50 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.00it/s]\n",
            "100% 47/47 [00:02<00:00, 18.29it/s]\n",
            "Epoch: 51 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.63it/s]\n",
            "100% 47/47 [00:03<00:00, 11.90it/s]\n",
            "Epoch: 52 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.53it/s]\n",
            "100% 47/47 [00:02<00:00, 16.83it/s]\n",
            "Epoch: 53 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.63it/s]\n",
            "100% 47/47 [00:02<00:00, 23.19it/s]\n",
            "Epoch: 54 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.71it/s]\n",
            "100% 47/47 [00:02<00:00, 23.03it/s]\n",
            "Epoch: 55 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.64it/s]\n",
            "100% 47/47 [00:02<00:00, 23.00it/s]\n",
            "Epoch: 56 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.82it/s]\n",
            "100% 47/47 [00:02<00:00, 23.14it/s]\n",
            "Epoch: 57 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.66it/s]\n",
            "100% 47/47 [00:02<00:00, 23.25it/s]\n",
            "Epoch: 58 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 20.92it/s]\n",
            "100% 47/47 [00:02<00:00, 22.65it/s]\n",
            "Epoch: 59 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.19it/s]\n",
            "100% 47/47 [00:02<00:00, 16.63it/s]\n",
            "Epoch: 60 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.89it/s]\n",
            "100% 47/47 [00:02<00:00, 16.76it/s]\n",
            "Epoch: 61 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.46it/s]\n",
            "100% 47/47 [00:02<00:00, 23.08it/s]\n",
            "Epoch: 62 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 17.89it/s]\n",
            "100% 47/47 [00:02<00:00, 23.47it/s]\n",
            "Epoch: 63 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.49it/s]\n",
            "100% 47/47 [00:02<00:00, 22.61it/s]\n",
            "Epoch: 64 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.84it/s]\n",
            "100% 47/47 [00:02<00:00, 22.71it/s]\n",
            "Epoch: 65 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.62it/s]\n",
            "100% 47/47 [00:02<00:00, 22.08it/s]\n",
            "Epoch: 66 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.25it/s]\n",
            "100% 47/47 [00:02<00:00, 19.56it/s]\n",
            "Epoch: 67 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 24.02it/s]\n",
            "100% 47/47 [00:03<00:00, 15.19it/s]\n",
            "Epoch: 68 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.76it/s]\n",
            "100% 47/47 [00:02<00:00, 20.15it/s]\n",
            "Epoch: 69 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.99it/s]\n",
            "100% 47/47 [00:02<00:00, 22.94it/s]\n",
            "Epoch: 70 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.55it/s]\n",
            "100% 47/47 [00:02<00:00, 22.66it/s]\n",
            "Epoch: 71 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.53it/s]\n",
            "100% 47/47 [00:02<00:00, 23.10it/s]\n",
            "Epoch: 72 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.64it/s]\n",
            "100% 47/47 [00:02<00:00, 23.02it/s]\n",
            "Epoch: 73 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.71it/s]\n",
            "100% 47/47 [00:02<00:00, 16.76it/s]\n",
            "Epoch: 74 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.77it/s]\n",
            "100% 47/47 [00:02<00:00, 22.91it/s]\n",
            "Epoch: 75 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.97it/s]\n",
            "100% 47/47 [00:02<00:00, 17.28it/s]\n",
            "Epoch: 76 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.59it/s]\n",
            "100% 47/47 [00:02<00:00, 15.84it/s]\n",
            "Epoch: 77 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.71it/s]\n",
            "100% 47/47 [00:02<00:00, 22.94it/s]\n",
            "Epoch: 78 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.13it/s]\n",
            "100% 47/47 [00:02<00:00, 22.89it/s]\n",
            "Epoch: 79 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.43it/s]\n",
            "100% 47/47 [00:02<00:00, 23.11it/s]\n",
            "Epoch: 80 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.48it/s]\n",
            "100% 47/47 [00:02<00:00, 19.00it/s]\n",
            "Epoch: 81 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.61it/s]\n",
            "100% 47/47 [00:02<00:00, 23.18it/s]\n",
            "Epoch: 82 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.59it/s]\n",
            "100% 47/47 [00:02<00:00, 22.72it/s]\n",
            "Epoch: 83 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 20.98it/s]\n",
            "100% 47/47 [00:02<00:00, 23.09it/s]\n",
            "Epoch: 84 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.28it/s]\n",
            "100% 47/47 [00:02<00:00, 17.80it/s]\n",
            "Epoch: 85 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.84it/s]\n",
            "100% 47/47 [00:03<00:00, 15.65it/s]\n",
            "Epoch: 86 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.69it/s]\n",
            "100% 47/47 [00:02<00:00, 20.09it/s]\n",
            "Epoch: 87 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.89it/s]\n",
            "100% 47/47 [00:02<00:00, 22.92it/s]\n",
            "Epoch: 88 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.68it/s]\n",
            "100% 47/47 [00:02<00:00, 22.80it/s]\n",
            "Epoch: 89 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.36it/s]\n",
            "100% 47/47 [00:02<00:00, 23.07it/s]\n",
            "Epoch: 90 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.87it/s]\n",
            "100% 47/47 [00:02<00:00, 22.98it/s]\n",
            "Epoch: 91 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.64it/s]\n",
            "100% 47/47 [00:02<00:00, 22.64it/s]\n",
            "Epoch: 92 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.43it/s]\n",
            "100% 47/47 [00:02<00:00, 20.49it/s]\n",
            "Epoch: 93 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 24.01it/s]\n",
            "100% 47/47 [00:03<00:00, 14.84it/s]\n",
            "Epoch: 94 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.86it/s]\n",
            "100% 47/47 [00:02<00:00, 17.52it/s]\n",
            "Epoch: 95 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.91it/s]\n",
            "100% 47/47 [00:02<00:00, 22.90it/s]\n",
            "Epoch: 96 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.71it/s]\n",
            "100% 47/47 [00:02<00:00, 22.89it/s]\n",
            "Epoch: 97 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.52it/s]\n",
            "100% 47/47 [00:02<00:00, 22.99it/s]\n",
            "Epoch: 98 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.59it/s]\n",
            "100% 47/47 [00:02<00:00, 22.69it/s]\n",
            "Epoch: 99 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 17.95it/s]\n",
            "100% 47/47 [00:02<00:00, 22.10it/s]\n",
            "Epoch: 100 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.73it/s]\n",
            "100% 47/47 [00:02<00:00, 22.76it/s]\n",
            "Epoch: 101 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.62it/s]\n",
            "100% 47/47 [00:02<00:00, 17.29it/s]\n",
            "Epoch: 102 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.61it/s]\n",
            "100% 47/47 [00:02<00:00, 16.11it/s]\n",
            "Epoch: 103 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 24.03it/s]\n",
            "100% 47/47 [00:02<00:00, 21.99it/s]\n",
            "Epoch: 104 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.58it/s]\n",
            "100% 47/47 [00:02<00:00, 22.80it/s]\n",
            "Epoch: 105 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.32it/s]\n",
            "100% 47/47 [00:02<00:00, 22.86it/s]\n",
            "Epoch: 106 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.63it/s]\n",
            "100% 47/47 [00:02<00:00, 22.38it/s]\n",
            "Epoch: 107 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.77it/s]\n",
            "100% 47/47 [00:02<00:00, 22.09it/s]\n",
            "Epoch: 108 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.74it/s]\n",
            "100% 47/47 [00:02<00:00, 22.98it/s]\n",
            "Epoch: 109 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.20it/s]\n",
            "100% 47/47 [00:02<00:00, 19.38it/s]\n",
            "Epoch: 110 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.35it/s]\n",
            "100% 47/47 [00:03<00:00, 15.20it/s]\n",
            "Epoch: 111 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.72it/s]\n",
            "100% 47/47 [00:02<00:00, 18.68it/s]\n",
            "Epoch: 112 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.03it/s]\n",
            "100% 47/47 [00:02<00:00, 22.55it/s]\n",
            "Epoch: 113 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.44it/s]\n",
            "100% 47/47 [00:02<00:00, 22.60it/s]\n",
            "Epoch: 114 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.65it/s]\n",
            "100% 47/47 [00:02<00:00, 23.06it/s]\n",
            "Epoch: 115 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.47it/s]\n",
            "100% 47/47 [00:02<00:00, 22.65it/s]\n",
            "Epoch: 116 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.67it/s]\n",
            "100% 47/47 [00:02<00:00, 22.75it/s]\n",
            "Epoch: 117 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.67it/s]\n",
            "100% 47/47 [00:02<00:00, 22.69it/s]\n",
            "Epoch: 118 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 18.15it/s]\n",
            "100% 47/47 [00:02<00:00, 22.79it/s]\n",
            "Epoch: 119 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.74it/s]\n",
            "100% 47/47 [00:02<00:00, 17.03it/s]\n",
            "Epoch: 120 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.89it/s]\n",
            "100% 47/47 [00:03<00:00, 14.99it/s]\n",
            "Epoch: 121 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.39it/s]\n",
            "100% 47/47 [00:02<00:00, 21.94it/s]\n",
            "Epoch: 122 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.02it/s]\n",
            "100% 47/47 [00:02<00:00, 22.74it/s]\n",
            "Epoch: 123 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.53it/s]\n",
            "100% 47/47 [00:02<00:00, 23.08it/s]\n",
            "Epoch: 124 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.63it/s]\n",
            "100% 47/47 [00:02<00:00, 23.00it/s]\n",
            "Epoch: 125 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.85it/s]\n",
            "100% 47/47 [00:02<00:00, 22.65it/s]\n",
            "Epoch: 126 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.52it/s]\n",
            "100% 47/47 [00:02<00:00, 22.51it/s]\n",
            "Epoch: 127 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.54it/s]\n",
            "100% 47/47 [00:02<00:00, 20.40it/s]\n",
            "Epoch: 128 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.59it/s]\n",
            "100% 47/47 [00:02<00:00, 18.61it/s]\n",
            "Epoch: 129 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.54it/s]\n",
            "100% 47/47 [00:03<00:00, 15.10it/s]\n",
            "Epoch: 130 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.71it/s]\n",
            "100% 47/47 [00:03<00:00, 14.24it/s]\n",
            "Epoch: 131 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.91it/s]\n",
            "100% 47/47 [00:02<00:00, 18.98it/s]\n",
            "Epoch: 132 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.82it/s]\n",
            "100% 47/47 [00:02<00:00, 22.01it/s]\n",
            "Epoch: 133 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.08it/s]\n",
            "100% 47/47 [00:02<00:00, 22.28it/s]\n",
            "Epoch: 134 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.99it/s]\n",
            "100% 47/47 [00:02<00:00, 22.49it/s]\n",
            "Epoch: 135 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.14it/s]\n",
            "100% 47/47 [00:02<00:00, 22.33it/s]\n",
            "Epoch: 136 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 17.83it/s]\n",
            "100% 47/47 [00:02<00:00, 22.23it/s]\n",
            "Epoch: 137 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.88it/s]\n",
            "100% 47/47 [00:02<00:00, 21.85it/s]\n",
            "Epoch: 138 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.19it/s]\n",
            "100% 47/47 [00:02<00:00, 22.40it/s]\n",
            "Epoch: 139 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.12it/s]\n",
            "100% 47/47 [00:02<00:00, 22.28it/s]\n",
            "Epoch: 140 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.55it/s]\n",
            "100% 47/47 [00:02<00:00, 18.85it/s]\n",
            "Epoch: 141 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.87it/s]\n",
            "100% 47/47 [00:03<00:00, 14.53it/s]\n",
            "Epoch: 142 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.29it/s]\n",
            "100% 47/47 [00:03<00:00, 15.32it/s]\n",
            "Epoch: 143 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.04it/s]\n",
            "100% 47/47 [00:02<00:00, 20.59it/s]\n",
            "Epoch: 144 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.39it/s]\n",
            "100% 47/47 [00:02<00:00, 22.08it/s]\n",
            "Epoch: 145 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.10it/s]\n",
            "100% 47/47 [00:02<00:00, 22.21it/s]\n",
            "Epoch: 146 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.90it/s]\n",
            "100% 47/47 [00:02<00:00, 22.12it/s]\n",
            "Epoch: 147 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.90it/s]\n",
            "100% 47/47 [00:02<00:00, 16.74it/s]\n",
            "Epoch: 148 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.05it/s]\n",
            "100% 47/47 [00:02<00:00, 21.37it/s]\n",
            "Epoch: 149 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.78it/s]\n",
            "100% 47/47 [00:02<00:00, 21.89it/s]\n",
            "Epoch: 150 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 18.38it/s]\n",
            "100% 47/47 [00:02<00:00, 22.25it/s]\n",
            "Epoch: 151 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.98it/s]\n",
            "100% 47/47 [00:02<00:00, 22.48it/s]\n",
            "Epoch: 152 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.56it/s]\n",
            "100% 47/47 [00:02<00:00, 18.28it/s]\n",
            "Epoch: 153 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.16it/s]\n",
            "100% 47/47 [00:03<00:00, 13.89it/s]\n",
            "Epoch: 154 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:07<00:00, 23.52it/s]\n",
            "100% 47/47 [00:02<00:00, 17.62it/s]\n",
            "Epoch: 155 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.28it/s]\n",
            "100% 47/47 [00:02<00:00, 17.22it/s]\n",
            "Epoch: 156 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.98it/s]\n",
            "100% 47/47 [00:02<00:00, 22.38it/s]\n",
            "Epoch: 157 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.81it/s]\n",
            "100% 47/47 [00:02<00:00, 22.04it/s]\n",
            "Epoch: 158 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.12it/s]\n",
            "100% 47/47 [00:02<00:00, 21.44it/s]\n",
            "Epoch: 159 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.14it/s]\n",
            "100% 47/47 [00:02<00:00, 22.16it/s]\n",
            "Epoch: 160 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.12it/s]\n",
            "100% 47/47 [00:02<00:00, 22.27it/s]\n",
            "Epoch: 161 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.92it/s]\n",
            "100% 47/47 [00:02<00:00, 21.93it/s]\n",
            "Epoch: 162 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.08it/s]\n",
            "100% 47/47 [00:02<00:00, 21.99it/s]\n",
            "Epoch: 163 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.78it/s]\n",
            "100% 47/47 [00:02<00:00, 18.74it/s]\n",
            "Epoch: 164 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.68it/s]\n",
            "100% 47/47 [00:02<00:00, 16.04it/s]\n",
            "Epoch: 165 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.08it/s]\n",
            "100% 47/47 [00:03<00:00, 15.38it/s]\n",
            "Epoch: 166 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.54it/s]\n",
            "100% 47/47 [00:02<00:00, 20.66it/s]\n",
            "Epoch: 167 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.30it/s]\n",
            "100% 47/47 [00:02<00:00, 21.20it/s]\n",
            "Epoch: 168 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.19it/s]\n",
            "100% 47/47 [00:02<00:00, 22.55it/s]\n",
            "Epoch: 169 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.07it/s]\n",
            "100% 47/47 [00:02<00:00, 22.02it/s]\n",
            "Epoch: 170 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.36it/s]\n",
            "100% 47/47 [00:02<00:00, 22.63it/s]\n",
            "Epoch: 171 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.98it/s]\n",
            "100% 47/47 [00:02<00:00, 22.04it/s]\n",
            "Epoch: 172 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.95it/s]\n",
            "100% 47/47 [00:02<00:00, 21.79it/s]\n",
            "Epoch: 173 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 17.29it/s]\n",
            "100% 47/47 [00:02<00:00, 21.59it/s]\n",
            "Epoch: 174 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.10it/s]\n",
            "100% 47/47 [00:02<00:00, 18.67it/s]\n",
            "Epoch: 175 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.05it/s]\n",
            "100% 47/47 [00:03<00:00, 14.77it/s]\n",
            "Epoch: 176 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.07it/s]\n",
            "100% 47/47 [00:02<00:00, 15.86it/s]\n",
            "Epoch: 177 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0366 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.49it/s]\n",
            "100% 47/47 [00:02<00:00, 22.35it/s]\n",
            "Epoch: 178 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0369 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 20.91it/s]\n",
            "100% 47/47 [00:02<00:00, 22.20it/s]\n",
            "Epoch: 179 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 18.49it/s]\n",
            "100% 47/47 [00:02<00:00, 21.78it/s]\n",
            "Epoch: 180 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.03it/s]\n",
            "100% 47/47 [00:02<00:00, 22.37it/s]\n",
            "Epoch: 181 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.02it/s]\n",
            "100% 47/47 [00:02<00:00, 22.42it/s]\n",
            "Epoch: 182 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.22it/s]\n",
            "100% 47/47 [00:02<00:00, 22.50it/s]\n",
            "Epoch: 183 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.01it/s]\n",
            "100% 47/47 [00:02<00:00, 16.54it/s]\n",
            "Epoch: 184 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.88it/s]\n",
            "100% 47/47 [00:02<00:00, 22.44it/s]\n",
            "Epoch: 185 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.53it/s]\n",
            "100% 47/47 [00:02<00:00, 21.71it/s]\n",
            "Epoch: 186 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.32it/s]\n",
            "100% 47/47 [00:02<00:00, 17.94it/s]\n",
            "Epoch: 187 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.21it/s]\n",
            "100% 47/47 [00:03<00:00, 14.72it/s]\n",
            "Epoch: 188 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 23.34it/s]\n",
            "100% 47/47 [00:02<00:00, 18.42it/s]\n",
            "Epoch: 189 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 21.60it/s]\n",
            "100% 47/47 [00:02<00:00, 22.53it/s]\n",
            "Epoch: 190 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.14it/s]\n",
            "100% 47/47 [00:02<00:00, 22.72it/s]\n",
            "Epoch: 191 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:10<00:00, 17.53it/s]\n",
            "100% 47/47 [00:02<00:00, 22.01it/s]\n",
            "Epoch: 192 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.87it/s]\n",
            "100% 47/47 [00:02<00:00, 22.03it/s]\n",
            "Epoch: 193 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.04it/s]\n",
            "100% 47/47 [00:02<00:00, 21.93it/s]\n",
            "Epoch: 194 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.94it/s]\n",
            "100% 47/47 [00:02<00:00, 22.20it/s]\n",
            "Epoch: 195 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.08it/s]\n",
            "100% 47/47 [00:02<00:00, 22.55it/s]\n",
            "Epoch: 196 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 19.95it/s]\n",
            "100% 47/47 [00:02<00:00, 22.35it/s]\n",
            "Epoch: 197 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:09<00:00, 20.80it/s]\n",
            "100% 47/47 [00:02<00:00, 19.78it/s]\n",
            "Epoch: 198 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.68it/s]\n",
            "100% 47/47 [00:02<00:00, 16.40it/s]\n",
            "Epoch: 199 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0367 \tValidation Accuracy: 19.8383\n",
            "100% 188/188 [00:08<00:00, 22.95it/s]\n",
            "100% 47/47 [00:03<00:00, 14.71it/s]\n",
            "Epoch: 200 \tTraining Loss: 0.0024 \tTraining Accuracy: 79.9633 \tValidation Loss: 0.0368 \tValidation Accuracy: 19.8383\n"
          ]
        }
      ],
      "source": [
        "!python main_normal.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRlCkechUGz3"
      },
      "source": [
        "### Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DmpYgHF35Vr",
        "outputId": "0a9e6009-1ee9-42d2-fbfe-5d485ab30893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-08 21:28:18.669552: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-08 21:28:19.550774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Parameters initialized\n",
            "100% 188/188 [03:47<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 1 \tTraining Loss: 0.2305 \tTraining Accuracy: 74.3450 \tValidation Loss: 0.3694 \tValidation Accuracy: 17.7533\n",
            "Validation loss decreased (inf --> 0.369373).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.67it/s]\n",
            "Epoch: 2 \tTraining Loss: 0.0540 \tTraining Accuracy: 78.6450 \tValidation Loss: 0.1277 \tValidation Accuracy: 19.1867\n",
            "Validation loss decreased (0.369373 --> 0.127735).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 3 \tTraining Loss: 0.0416 \tTraining Accuracy: 78.9550 \tValidation Loss: 0.3387 \tValidation Accuracy: 18.0800\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 4 \tTraining Loss: 0.0367 \tTraining Accuracy: 79.0717 \tValidation Loss: 0.1739 \tValidation Accuracy: 18.9500\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 5 \tTraining Loss: 0.0296 \tTraining Accuracy: 79.2283 \tValidation Loss: 0.0891 \tValidation Accuracy: 19.5133\n",
            "Validation loss decreased (0.127735 --> 0.089078).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 6 \tTraining Loss: 0.0295 \tTraining Accuracy: 79.2650 \tValidation Loss: 0.0932 \tValidation Accuracy: 19.4283\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 7 \tTraining Loss: 0.0238 \tTraining Accuracy: 79.3817 \tValidation Loss: 0.0897 \tValidation Accuracy: 19.4667\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 8 \tTraining Loss: 0.0232 \tTraining Accuracy: 79.4250 \tValidation Loss: 0.1039 \tValidation Accuracy: 19.3433\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 9 \tTraining Loss: 0.0222 \tTraining Accuracy: 79.4200 \tValidation Loss: 0.0544 \tValidation Accuracy: 19.6850\n",
            "Validation loss decreased (0.089078 --> 0.054400).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.67it/s]\n",
            "Epoch: 10 \tTraining Loss: 0.0189 \tTraining Accuracy: 79.4817 \tValidation Loss: 0.0565 \tValidation Accuracy: 19.6833\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 11 \tTraining Loss: 0.0175 \tTraining Accuracy: 79.5500 \tValidation Loss: 0.0543 \tValidation Accuracy: 19.7367\n",
            "Validation loss decreased (0.054400 --> 0.054350).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 12 \tTraining Loss: 0.0192 \tTraining Accuracy: 79.4867 \tValidation Loss: 0.0661 \tValidation Accuracy: 19.5917\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 13 \tTraining Loss: 0.0138 \tTraining Accuracy: 79.6467 \tValidation Loss: 0.0496 \tValidation Accuracy: 19.7233\n",
            "Validation loss decreased (0.054350 --> 0.049587).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 14 \tTraining Loss: 0.0131 \tTraining Accuracy: 79.6817 \tValidation Loss: 0.1609 \tValidation Accuracy: 19.1233\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 15 \tTraining Loss: 0.0171 \tTraining Accuracy: 79.5517 \tValidation Loss: 0.0544 \tValidation Accuracy: 19.7050\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 16 \tTraining Loss: 0.0134 \tTraining Accuracy: 79.6583 \tValidation Loss: 0.0680 \tValidation Accuracy: 19.6550\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 17 \tTraining Loss: 0.0143 \tTraining Accuracy: 79.6300 \tValidation Loss: 0.0549 \tValidation Accuracy: 19.7267\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 18 \tTraining Loss: 0.0118 \tTraining Accuracy: 79.7017 \tValidation Loss: 0.0658 \tValidation Accuracy: 19.6233\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 19 \tTraining Loss: 0.0107 \tTraining Accuracy: 79.7117 \tValidation Loss: 0.0387 \tValidation Accuracy: 19.7817\n",
            "Validation loss decreased (0.049587 --> 0.038692).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 20 \tTraining Loss: 0.0097 \tTraining Accuracy: 79.7517 \tValidation Loss: 0.0521 \tValidation Accuracy: 19.7317\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 21 \tTraining Loss: 0.0110 \tTraining Accuracy: 79.6883 \tValidation Loss: 0.0503 \tValidation Accuracy: 19.7633\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 22 \tTraining Loss: 0.0086 \tTraining Accuracy: 79.7567 \tValidation Loss: 0.1235 \tValidation Accuracy: 19.3533\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 23 \tTraining Loss: 0.0073 \tTraining Accuracy: 79.8033 \tValidation Loss: 0.0755 \tValidation Accuracy: 19.6567\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 24 \tTraining Loss: 0.0062 \tTraining Accuracy: 79.8450 \tValidation Loss: 0.0579 \tValidation Accuracy: 19.7200\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 25 \tTraining Loss: 0.0078 \tTraining Accuracy: 79.8067 \tValidation Loss: 0.0720 \tValidation Accuracy: 19.6383\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch 00026: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 26 \tTraining Loss: 0.0100 \tTraining Accuracy: 79.7167 \tValidation Loss: 0.0605 \tValidation Accuracy: 19.7550\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.67it/s]\n",
            "Epoch: 27 \tTraining Loss: 0.0043 \tTraining Accuracy: 79.8933 \tValidation Loss: 0.0311 \tValidation Accuracy: 19.8800\n",
            "Validation loss decreased (0.038692 --> 0.031085).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 28 \tTraining Loss: 0.0011 \tTraining Accuracy: 79.9750 \tValidation Loss: 0.0304 \tValidation Accuracy: 19.8750\n",
            "Validation loss decreased (0.031085 --> 0.030376).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 29 \tTraining Loss: 0.0006 \tTraining Accuracy: 79.9933 \tValidation Loss: 0.0308 \tValidation Accuracy: 19.8717\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 30 \tTraining Loss: 0.0005 \tTraining Accuracy: 79.9933 \tValidation Loss: 0.0305 \tValidation Accuracy: 19.8733\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 31 \tTraining Loss: 0.0004 \tTraining Accuracy: 79.9967 \tValidation Loss: 0.0296 \tValidation Accuracy: 19.8800\n",
            "Validation loss decreased (0.030376 --> 0.029596).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 32 \tTraining Loss: 0.0003 \tTraining Accuracy: 79.9983 \tValidation Loss: 0.0301 \tValidation Accuracy: 19.8800\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 33 \tTraining Loss: 0.0003 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0303 \tValidation Accuracy: 19.8783\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 34 \tTraining Loss: 0.0003 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0296 \tValidation Accuracy: 19.8850\n",
            "Validation loss decreased (0.029596 --> 0.029592).  Saving model ...\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 35 \tTraining Loss: 0.0002 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0300 \tValidation Accuracy: 19.8817\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 36 \tTraining Loss: 0.0002 \tTraining Accuracy: 79.9983 \tValidation Loss: 0.0301 \tValidation Accuracy: 19.8850\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 37 \tTraining Loss: 0.0002 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0307 \tValidation Accuracy: 19.8783\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 38 \tTraining Loss: 0.0002 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0303 \tValidation Accuracy: 19.8800\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 39 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0300 \tValidation Accuracy: 19.8800\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 40 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0303 \tValidation Accuracy: 19.8800\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch 00041: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 41 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0303 \tValidation Accuracy: 19.8817\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.63it/s]\n",
            "Epoch: 42 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0312 \tValidation Accuracy: 19.8800\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 43 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0309 \tValidation Accuracy: 19.8850\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 44 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0313 \tValidation Accuracy: 19.8783\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 45 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0310 \tValidation Accuracy: 19.8833\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 46 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0309 \tValidation Accuracy: 19.8817\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.62it/s]\n",
            "Epoch: 47 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0314 \tValidation Accuracy: 19.8783\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch 00048: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 48 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0309 \tValidation Accuracy: 19.8800\n",
            "100% 188/188 [03:46<00:00,  1.21s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 49 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0304 \tValidation Accuracy: 19.8817\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 50 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0312 \tValidation Accuracy: 19.8767\n",
            "100% 188/188 [03:45<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.65it/s]\n",
            "Epoch: 51 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0307 \tValidation Accuracy: 19.8817\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.64it/s]\n",
            "Epoch: 52 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0305 \tValidation Accuracy: 19.8817\n",
            "100% 188/188 [03:46<00:00,  1.20s/it]\n",
            "100% 47/47 [00:17<00:00,  2.66it/s]\n",
            "Epoch: 53 \tTraining Loss: 0.0001 \tTraining Accuracy: 80.0000 \tValidation Loss: 0.0310 \tValidation Accuracy: 19.8783\n",
            " 93% 175/188 [03:31<00:15,  1.20s/it]"
          ]
        }
      ],
      "source": [
        "!python main_normal.py --net_type resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiiYueVSULRb"
      },
      "source": [
        "### VGG11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd06LXQA3_ws"
      },
      "outputs": [],
      "source": [
        "!python main_normal.py --net_type vgg11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgLSIZEoUN2s"
      },
      "source": [
        "### Custom CNN - 4conv3fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaq46--Z4EKW"
      },
      "outputs": [],
      "source": [
        "!python main_normal.py --net_type 4conv3fc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuihxPTiURSW"
      },
      "source": [
        "### Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55aCQ-Ki4EG5"
      },
      "outputs": [],
      "source": [
        "!python main_normal.py --net_type alexnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcCJx_8wx4Jo"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkOZbiMkKa3c",
        "outputId": "493dbb7c-c1bc-4cf5-9665-bb17e9f5388d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/MNIST/ (stored 0%)\n",
            "  adding: content/checkpoints/MNIST/frequentist/ (stored 0%)\n",
            "  adding: content/checkpoints/MNIST/frequentist/model_lenet.pt (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/checkpoints.zip /content/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nyirCgB5Kjrl",
        "outputId": "f6d8f3e4-3ff7-4258-a65f-8b489db2dd52"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5b8c9c9f-c887-4610-a2d9-1b047cc49796\", \"checkpoints.zip\", 231329)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/checkpoints.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbR0gVcUG5-M",
        "outputId": "ceb1b215-4304-4d24-fe31-d568889a5887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/lenet-MNIST/ (stored 0%)\n",
            "  adding: content/lenet-MNIST/events.out.tfevents.1682996959.ebe7c2793a35.1026.0 (deflated 70%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/ln_mnist.zip /content/lenet-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3xK1aboJG5-N",
        "outputId": "5ff4cf55-cbbd-483e-959f-1fed6e24d8b1"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_827aa8e6-1aa5-4639-beae-e0e9bcb2755c\", \"ln_mnist.zip\", 12291)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/ln_mnist.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "7a14979e061517ff8db1e3d4e5b2588024b75be1831ccaffba4da2ed3a779201"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
